{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 8094,
     "status": "ok",
     "timestamp": 1746911840500,
     "user": {
      "displayName": "전민규",
      "userId": "14545444950541885596"
     },
     "user_tz": -540
    },
    "id": "9KkqF5aaDMXL"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F # F.cross_entropy를 위해 추가\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, BitsAndBytesConfig # BitsAndBytesConfig 추가\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType # peft 관련 모듈 추가\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import random_split\n",
    "import random\n",
    "import itertools\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 라이브러리의 시드가 42로 고정되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 시드 값 설정 (원하는 정수 값으로 설정)\n",
    "SEED = 42\n",
    "\n",
    "def set_seeds(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)  # 여러 GPU 사용 시\n",
    "        # CUDA 연산의 결정론적 실행 설정 (성능에 약간 영향 줄 수 있음)\n",
    "        # torch.backends.cudnn.deterministic = True\n",
    "        # torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seeds(SEED)\n",
    "print(f\"모든 라이브러리의 시드가 {SEED}로 고정되었습니다.\")\n",
    "\n",
    "# DataLoader의 worker_init_fn 설정 (데이터 로딩 순서 재현성)\n",
    "# def seed_worker(worker_id):\n",
    "#     worker_seed = torch.initial_seed() % 2**32\n",
    "#     np.random.seed(worker_seed)\n",
    "#     random.seed(worker_seed)\n",
    "\n",
    "# DataLoader 초기화 시 worker_init_fn 추가 (필요한 경우)\n",
    "# train_dataloader = DataLoader(..., worker_init_fn=seed_worker)\n",
    "# val_dataloader = DataLoader(..., worker_init_fn=seed_worker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1746911840503,
     "user": {
      "displayName": "전민규",
      "userId": "14545444950541885596"
     },
     "user_tz": -540
    },
    "id": "fVidmPYUNKY6"
   },
   "outputs": [],
   "source": [
    "# --- 2. EEG Dataset ---\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 data_dir = \"/workspace/dataset/combined_dataset.parquet\"):\n",
    "        df = pd.read_parquet(data_dir)\n",
    "        eeg_vecs = df[\"eeg\"].to_numpy()\n",
    "\n",
    "        arr = np.stack(eeg_vecs).astype(np.float32)\n",
    "        arr = np.nan_to_num(arr, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        mu, std = arr.mean(0, keepdims=True), arr.std(0, keepdims=True)+1e-8\n",
    "        self.eeg_arr = (arr - mu) / std      # 정규화\n",
    "        self.text_arr = df[\"text\"].to_numpy() # 텍스트 데이터\n",
    "        self.data = list(zip(torch.tensor(self.eeg_arr), self.text_arr))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1746911840508,
     "user": {
      "displayName": "전민규",
      "userId": "14545444950541885596"
     },
     "user_tz": -540
    },
    "id": "i5WIbZ6RQds4"
   },
   "outputs": [],
   "source": [
    "class ConvEEGEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    840-dim 벡터를 1×840 시퀀스로 보고 Conv1D 두 층으로 잠재표현 생성\n",
    "    출력은 (B, latent_dim)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=840, latent_dim=64, hidden=256):\n",
    "        super().__init__()\n",
    "        self.conv_stack = nn.Sequential(\n",
    "            nn.Conv1d(1, hidden, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.Conv1d(hidden, latent_dim, kernel_size=3, padding=1), nn.ReLU()\n",
    "        )\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)   # 길이 840 → 1 로 압축\n",
    "\n",
    "    def forward(self, x):           # x: (B, feat)\n",
    "        x = x.unsqueeze(1)          # (B, 1, 840)\n",
    "        z = self.conv_stack(x)      # (B, latent_dim, 840)\n",
    "        z = self.pool(z).squeeze(-1)  # (B, latent_dim)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1746911840509,
     "user": {
      "displayName": "전민규",
      "userId": "14545444950541885596"
     },
     "user_tz": -540
    },
    "id": "YFUIEJEdQjIb"
   },
   "outputs": [],
   "source": [
    "\n",
    "class RVQ(nn.Module):\n",
    "    def __init__(self, num_quantizers, num_embeddings, embedding_dim, commitment_cost=0.25):\n",
    "        super().__init__()\n",
    "        self.num_quantizers = num_quantizers # 코드북의 개수 (n_q)\n",
    "        self.num_embeddings = num_embeddings # 각 코드북 내 임베딩(코드워드) 개수 (n_emb, 어휘 크기)\n",
    "        self.embedding_dim = embedding_dim   # 각 임베딩의 차원 (D, latent_dim과 동일)\n",
    "        self.commitment_cost = commitment_cost # VQ 손실 계산 시 사용되는 하이퍼파라미터\n",
    "\n",
    "        # num_quantizers 개수만큼의 코드북(nn.Embedding 레이어)을 리스트로 가짐\n",
    "        self.codebooks = nn.ModuleList([\n",
    "            nn.Embedding(self.num_embeddings, self.embedding_dim) for _ in range(self.num_quantizers)\n",
    "        ])\n",
    "        # 코드북 가중치 초기화 (선택 사항이지만 일반적으로 수행)\n",
    "        for i, codebook in enumerate(self.codebooks):\n",
    "            nn.init.uniform_(codebook.weight, -1.0 / self.num_embeddings, 1.0 / self.num_embeddings)\n",
    "\n",
    "    def forward(self, z_e): # 입력 z_e의 모양: (B, L, D), 여기서 L=1, D=embedding_dim\n",
    "        B, L, D = z_e.shape\n",
    "        z_e_flat = z_e.reshape(-1, D) # (B*L, D) 모양으로 펼침 (여기서는 (B, D)와 동일)\n",
    "\n",
    "        all_quantized_stages = [] # 각 코드북에서 양자화된 벡터들을 저장할 리스트\n",
    "        all_indices = []          # 각 코드북에서 선택된 인덱스들을 저장할 리스트\n",
    "        residual = z_e_flat       # 첫 번째 코드북에 입력될 잔차 (초기에는 z_e_flat 전체)\n",
    "\n",
    "        # num_quantizers 만큼 반복 (각 코드북에 대해 순차적으로 처리)\n",
    "        for i in range(self.num_quantizers):\n",
    "            codebook = self.codebooks[i] # 현재 사용할 코드북\n",
    "\n",
    "            # 현재 잔차(residual)와 현재 코드북의 모든 임베딩 간의 유클리드 거리 제곱 계산\n",
    "            # distances 모양: (B*L, num_embeddings)\n",
    "            distances = torch.sum(residual**2, dim=1, keepdim=True) \\\n",
    "                        - 2 * torch.matmul(residual, codebook.weight.t()) \\\n",
    "                        + torch.sum(codebook.weight**2, dim=1, keepdim=True).t()\n",
    "\n",
    "            # 가장 가까운 임베딩의 인덱스 찾기\n",
    "            # current_indices 모양: (B*L)\n",
    "            current_indices = torch.argmin(distances, dim=1)\n",
    "            all_indices.append(current_indices) # 현재 코드북의 인덱스 저장\n",
    "\n",
    "            # 선택된 인덱스를 사용하여 양자화된 벡터(코드워드) 가져오기\n",
    "            # quantized_vector 모양: (B*L, D)\n",
    "            quantized_vector = codebook(current_indices)\n",
    "            # 원래 모양 (B, L, D)로 복원하여 저장 (여기서는 (B, 1, D))\n",
    "            all_quantized_stages.append(quantized_vector.reshape(B, L, D))\n",
    "\n",
    "            # 다음 코드북으로 넘길 잔차 계산\n",
    "            # 중요: quantized_vector에서 그래디언트 흐름을 끊기 위해 .detach() 사용\n",
    "            residual = residual - quantized_vector.detach()\n",
    "\n",
    "        # 모든 코드북에서 나온 양자화된 벡터들을 합산 (EEGTran 논문 Figure 2 참조)\n",
    "        # final_quantized_output 모양: (B, L, D)\n",
    "        final_quantized_output = torch.stack(all_quantized_stages, dim=0).sum(dim=0)\n",
    "\n",
    "        # 수집된 인덱스들을 (B, L, num_quantizers) 형태로 쌓음\n",
    "        # stacked_indices 모양: (B, L, n_q) (여기서는 (B, 1, n_q))\n",
    "        stacked_indices = torch.stack(all_indices, dim=1).reshape(B, L, self.num_quantizers)\n",
    "\n",
    "        # 최종 반환값: 합산된 양자화 벡터, 쌓인 인덱스 시퀀스, VQ 손실\n",
    "        # RVQTokenizer의 forward에서는 이 중 첫 두 개를 zq, indices로 받게 됩니다.\n",
    "        return final_quantized_output, stacked_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1746911840514,
     "user": {
      "displayName": "전민규",
      "userId": "14545444950541885596"
     },
     "user_tz": -540
    },
    "id": "I0PnpRcHE2aX"
   },
   "outputs": [],
   "source": [
    "# --- 1. RVQ AutoEncoder (사용자가 제공한 정의, 여기서는 인코더와 RVQ 부분만 사용 가정) ---\n",
    "# 예시: 실제 사용 시에는 사용자의 ConvRVQAutoEncoder 클래스 정의를 가져오고, 학습된 가중치를 로드해야 합니다.\n",
    "# 이 클래스는 (B, 840) 입력을 받아 (B, n_q) 모양의 토큰 ID를 반환하는 get_eeg_token_ids 메소드를 가져야 합니다.\n",
    "class RVQTokenizer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 feat=840,\n",
    "                 latent=2048,\n",
    "                 n_q=64,\n",
    "                 n_emb=512,\n",
    "                 hidden=256,\n",
    "                 TOKENIZER_CHECKPOINT_PATH = \"/workspace/min/tokenizer/tokenizer_epoch005.pt\"\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.n_q = n_q\n",
    "        self.n_emb = n_emb\n",
    "        # 실제 ConvEEGEncoder와 RVQ 모듈이 여기에 와야 함\n",
    "        self.enc = ConvEEGEncoder(feat, latent, hidden)\n",
    "        self.rvq = RVQ(num_quantizers=n_q, num_embeddings=n_emb, embedding_dim=latent)\n",
    "\n",
    "        checkpoint = torch.load(TOKENIZER_CHECKPOINT_PATH, map_location=\"cpu\")\n",
    "        self.enc.load_state_dict(checkpoint[\"encoder\"])\n",
    "        for i, cb_weight_tensor in enumerate(checkpoint[\"codebooks\"]):\n",
    "          self.rvq.codebooks[i].weight.data = cb_weight_tensor\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, x): # x: (B, 840)\n",
    "        z = self.enc(x)\n",
    "        quantized_vector, token_indices = self.rvq(z.unsqueeze(1)) # vq_loss는 무시\n",
    "        zq = quantized_vector\n",
    "        indices = token_indices # 모양 (B, 1, n_q)\n",
    "        # 만약 LLaDA 입력용으로 (B, n_q) 모양의 인덱스를 원한다면 squeeze(1) 필요\n",
    "        # return zq, indices.squeeze(1)\n",
    "        return zq, indices # 현재 pasted_content.txt의 주석과 맞추려면 이대로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1746911840564,
     "user": {
      "displayName": "전민규",
      "userId": "14545444950541885596"
     },
     "user_tz": -540
    },
    "id": "_aTFEvBsGE61"
   },
   "outputs": [],
   "source": [
    "def forward_process_eeg(original_eeg_ids, mask_eeg_token_id = 126336, eps=1e-3):\n",
    "    # original_eeg_ids: (B, n_q) 모양의 EEG 토큰 ID\n",
    "    # mask_eeg_token_id: 우리가 정의한 EEG 마스크 토큰 ID (예: RVQ_N_EMB)\n",
    "    b, l = original_eeg_ids.shape\n",
    "\n",
    "    # 각 배치 샘플별로 랜덤한 t 값을 생성 (0~1)\n",
    "    # LLaDA 코드는 t를 (b)로 만들지만, 논문 Figure 2a는 t ~ U(0,1)로 단일 값을 의미하기도 합니다.\n",
    "    # 여기서는 LLaDA 코드 스타일을 따라 배치별 t를 사용합니다.\n",
    "    t_per_sample = torch.rand(b, device=original_eeg_ids.device)\n",
    "\n",
    "    # p_mask 계산: 각 샘플의 t 값에 따라 해당 샘플 내 모든 토큰에 적용될 마스킹 확률\n",
    "    # p_mask_per_sample의 모양: (b, 1)\n",
    "    p_mask_per_sample = (1 - eps) * t_per_sample + eps\n",
    "    # p_mask_for_tokens의 모양: (b, l)\n",
    "    p_mask_for_tokens = p_mask_per_sample.unsqueeze(-1).repeat(1, l)\n",
    "\n",
    "    # 각 토큰 위치별로 마스킹 여부 결정\n",
    "    # noise_for_masking의 모양: (b, l)\n",
    "    noise_for_masking = torch.rand((b, l), device=original_eeg_ids.device)\n",
    "    masked_indices = noise_for_masking < p_mask_for_tokens # True면 마스크\n",
    "\n",
    "    # 마스크된 입력 생성 (noisy_batch 역할)\n",
    "    masked_eeg_ids_for_input = torch.where(masked_indices, mask_eeg_token_id, original_eeg_ids)\n",
    "\n",
    "    return masked_eeg_ids_for_input, masked_indices # p_mask는 직접 필요 없으므로 반환 안 함 (필요시 추가)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1746911840565,
     "user": {
      "displayName": "전민규",
      "userId": "14545444950541885596"
     },
     "user_tz": -540
    },
    "id": "igJLxUVoGFak"
   },
   "outputs": [],
   "source": [
    "class EEG_LLaDA_MLM(nn.Module):\n",
    "  def __init__(self, llada_model_name, rvq_n_emb, use_qlora=True, qlora_config_params=None):\n",
    "    super().__init__()\n",
    "    self.rvq_n_emb = rvq_n_emb\n",
    "    self.llada_model_name = llada_model_name\n",
    "\n",
    "    bnb_config = None\n",
    "    if use_qlora:\n",
    "        bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16, # 또는 torch.float16\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "        )\n",
    "\n",
    "    # LLaDA 모델 로드 (양자화 설정 적용)\n",
    "    self.llada_model = AutoModelForCausalLM.from_pretrained(\n",
    "        llada_model_name,\n",
    "        quantization_config=bnb_config if use_qlora else None,\n",
    "        torch_dtype=torch.bfloat16 if use_qlora and bnb_config else \"auto\", # 양자화 시 bfloat16 사용 권장\n",
    "        trust_remote_code=True,\n",
    "        # device_map=\"auto\" # 여러 GPU 사용 시 또는 메모리 최적화 시 고려\n",
    "    )\n",
    "    self.llada_hidden_size = self.llada_model.config.hidden_size\n",
    "    model_dtype = self.llada_model.dtype\n",
    "\n",
    "    self.v_text = self.llada_model.config.vocab_size\n",
    "    num_new_eeg_tokens = self.rvq_n_emb + 1\n",
    "    new_total_vocab_size = self.v_text + num_new_eeg_tokens\n",
    "    print(f\"Original vocab size: {self.v_text}\")\n",
    "    print(f\"Resizing token embeddings to: {new_total_vocab_size}\")\n",
    "    self.llada_model.resize_token_embeddings(new_total_vocab_size)\n",
    "    print(f\"New vocab size: {self.llada_model.config.vocab_size}\") # 확인용\n",
    "    self.global_mask_eeg_token_id = self.v_text + self.rvq_n_emb\n",
    "\n",
    "    # QLoRA 적용\n",
    "    if use_qlora:\n",
    "        # 모델을 k-bit 학습용으로 준비 (양자화된 모델에 필요)\n",
    "        #self.llada_model = prepare_model_for_kbit_training(self.llada_model)\n",
    "\n",
    "        # LoRA 설정 정의\n",
    "        # target_modules는 모델마다 다를 수 있으므로 확인 필요 (아래 설명 참조)\n",
    "        default_target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
    "        if qlora_config_params and \"target_modules\" in qlora_config_params:\n",
    "            target_modules = qlora_config_params[\"target_modules\"]\n",
    "        else:\n",
    "            target_modules = default_target_modules\n",
    "\n",
    "        lora_config = LoraConfig(\n",
    "            r=qlora_config_params.get(\"r\", 16) if qlora_config_params else 16, # LoRA rank\n",
    "            lora_alpha=qlora_config_params.get(\"lora_alpha\", 32) if qlora_config_params else 32, # Alpha scaling\n",
    "            target_modules=target_modules,\n",
    "            lora_dropout=qlora_config_params.get(\"lora_dropout\", 0.05) if qlora_config_params else 0.05,\n",
    "            bias=\"none\", # LoRA는 보통 bias를 학습하지 않음\n",
    "            task_type=TaskType.CAUSAL_LM, # Causal LM 작업용\n",
    "        )\n",
    "        self.llada_model = get_peft_model(self.llada_model, lora_config)\n",
    "        print(\"QLoRA applied to LLaDA model.\")\n",
    "\n",
    "        print(\"Making input embeddings trainable for newly added tokens...\")\n",
    "        if hasattr(self.llada_model, 'base_model'): # PeftModel 경우\n",
    "            embedding_layer = self.llada_model.base_model.get_input_embeddings()\n",
    "        else: # 일반 모델 경우 (get_peft_model 이전)\n",
    "            embedding_layer = self.llada_model.get_input_embeddings()\n",
    "        \n",
    "        for param in embedding_layer.parameters():\n",
    "            param.requires_grad = True\n",
    "        print(\"Input embeddings are now trainable.\")\n",
    "        \n",
    "        self.llada_model.print_trainable_parameters() # 학습 가능한 파라미터 수 출력\n",
    "\n",
    "\n",
    "    self.mlm_head = nn.Linear(self.llada_hidden_size, self.rvq_n_emb, dtype=model_dtype)\n",
    "\n",
    "  def forward(self, masked_global_eeg_ids_for_input, attention_mask=None, mlm_labels=None):\n",
    "    model_outputs = self.llada_model(\n",
    "        input_ids=masked_global_eeg_ids_for_input,\n",
    "        attention_mask=attention_mask,\n",
    "        output_hidden_states=True,  # 중간 은닉 상태들을 출력하도록 요청\n",
    "        return_dict=True\n",
    "    )\n",
    "\n",
    "    # output_hidden_states=True로 설정하면, model_outputs.hidden_states 에 모든 레이어의 은닉 상태가 튜플 형태로 저장됩니다.\n",
    "    # 이 튜플의 마지막 요소가 우리가 원하는 last_hidden_state 입니다.\n",
    "    # (입력 임베딩 결과 + 각 트랜스포머 레이어의 출력 결과)\n",
    "    all_hidden_states = model_outputs.hidden_states\n",
    "    sequence_output = all_hidden_states[-1] # 마지막 트랜스포머 레이어의 출력\n",
    "\n",
    "    # --- 디버깅을 위한 print 문 (여전히 유효합니다) --- #\n",
    "    #print(f\"Shape of sequence_output (from hidden_states[-1]) before mlm_head: {sequence_output.shape}\")\n",
    "    # 이제 예상되는 모양: (batch_size, sequence_length, llada_hidden_size), 예: (1, 64, 4096)\n",
    "\n",
    "    mlm_logits = self.mlm_head(sequence_output)\n",
    "\n",
    "    loss = None\n",
    "    if mlm_labels is not None:\n",
    "        loss_fct = CrossEntropyLoss(ignore_index=-100)\n",
    "        loss = loss_fct(mlm_logits.view(-1, self.rvq_n_emb), mlm_labels.view(-1))\n",
    "\n",
    "    return {\n",
    "        \"loss\": loss,\n",
    "        \"logits\": mlm_logits,\n",
    "        # \"hidden_states\": sequence_output # 필요하다면 전체 hidden_states 튜플을 반환할 수도 있습니다.\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, device, rvq_tokenizer):\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    total_val_loss = 0\n",
    "    \n",
    "    with torch.no_grad(): # 그래디언트 계산 비활성화\n",
    "        for batch_eeg_tensors in dataloader:\n",
    "            batch_eeg_tensors = batch_eeg_tensors.to(device)\n",
    "\n",
    "            # 1. RVQ 토큰화\n",
    "            _, local_eeg_indices_batch = rvq_tokenizer(batch_eeg_tensors)\n",
    "            original_local_eeg_ids = local_eeg_indices_batch.squeeze(1)\n",
    "            \n",
    "            # 2. 글로벌 ID 변환 및 마스킹\n",
    "            global_original_eeg_ids = original_local_eeg_ids + model.v_text\n",
    "            masked_global_eeg_ids_for_input, masked_indices = forward_process_eeg(\n",
    "                global_original_eeg_ids, \n",
    "                model.global_mask_eeg_token_id\n",
    "            )\n",
    "\n",
    "            # 3. MLM 레이블 생성\n",
    "            mlm_labels = original_local_eeg_ids.clone()\n",
    "            mlm_labels[~masked_indices] = -100\n",
    "\n",
    "            # 4. 어텐션 마스크 생성\n",
    "            attention_mask = torch.ones_like(original_local_eeg_ids, device=device)\n",
    "\n",
    "            # 5. 모델 순전파 및 손실 계산\n",
    "            outputs = model(\n",
    "                masked_global_eeg_ids_for_input=masked_global_eeg_ids_for_input,\n",
    "                attention_mask=attention_mask,\n",
    "                mlm_labels=mlm_labels\n",
    "            )\n",
    "            loss = outputs[\"loss\"]\n",
    "            if loss is not None:\n",
    "                total_val_loss += loss.item()\n",
    "            else:\n",
    "                print(\"검증 중 손실이 None입니다.\") # 이 경우는 거의 없어야 함\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(dataloader)\n",
    "    model.train() # 모델을 다시 학습 모드로 설정\n",
    "    return avg_val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_eeg_mlm(batch):\n",
    "    eeg_tensors = [item[0] for item in batch] # item[0]이 eeg_tensor라고 가정\n",
    "    return torch.stack(eeg_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416,
     "referenced_widgets": [
      "6f28c65545ff48b7ba75e9baa7945ef5",
      "50f40a527f7e4d6c9af92a4e80136498",
      "64f3dc6feb69453ab5635b471a280b0c",
      "f7adee33a524499ead533248d3f4580c",
      "eba5ef1393884ffc99e76b42dfa7c4bb",
      "9e5e7118945440c0918a6ab2176f3512",
      "e3473cea30f545069983b0c09005840a",
      "1ef27ea2e0264c0e94520ea1e9ec47a9",
      "837b58da5af44e429cc334262d22cba5",
      "fc6bd1bd0ed14514afa3091399661903",
      "be5f991fb5844888b2b57cd35e8bbc00"
     ]
    },
    "executionInfo": {
     "elapsed": 24919,
     "status": "ok",
     "timestamp": 1746911865486,
     "user": {
      "displayName": "전민규",
      "userId": "14545444950541885596"
     },
     "user_tz": -540
    },
    "id": "_rO4y0HXeuOX",
    "outputId": "33b03e36-4f0d-4c00-daa8-02549c8f6c9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용 디바이스: cuda\n",
      "총 54개의 하이퍼파라미터 조합으로 그리드 서치를 수행합니다.\n",
      "\n",
      "--- 그리드 서치 조합 1/54 (combo_001_lr_0.0001_r_8_alpha_16_bs_32) 시작 ---\n",
      "현재 하이퍼파라미터: {'learning_rate': 0.0001, 'lora_r': 8, 'lora_alpha': 16, 'batch_size': 32, 'validation_split': 0.1}\n",
      "전체 데이터셋 크기: 25616\n",
      "학습 데이터셋 크기: 23055\n",
      "검증 데이터셋 크기: 2561\n",
      "학습 데이터로더 크기: 721\n",
      "검증 데이터로더 크기: 81\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db1944ad977a4e36b4d822672d7211bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vocab size: 126464\n",
      "Resizing token embeddings to: 126977\n",
      "New vocab size: 126977\n",
      "QLoRA applied to LLaDA model.\n",
      "Making input embeddings trainable for newly added tokens...\n",
      "Input embeddings are now trainable.\n",
      "trainable params: 524,292,096 || all params: 8,021,876,736 || trainable%: 6.5358\n",
      "\n",
      "옵티마이저를 위한 파라미터 수집 중:\n",
      "옵티마이저를 위한 총 파라미터 그룹 수: 131\n",
      "\n",
      "옵티마이저 및 스케줄러 설정 완료.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:306: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  조합 1, 에폭 1: Train Loss=0.6386, Val Loss=0.1918, LR=1.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:251: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    에폭 1 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_001_lr_0.0001_r_8_alpha_16_bs_32/epoch_1\n",
      "    조합 내 베스트 모델 갱신 (에폭 1), Val Loss: 0.1918. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_001_lr_0.0001_r_8_alpha_16_bs_32/best_model_in_combo\n",
      "    ✨ 전체 베스트 모델 갱신 (조합 1, 에폭 1), Val Loss: 0.1918. 저장 중...\n",
      "    ✨ 전체 베스트 모델 저장 완료: /workspace/min/pre_train/grid_search_results/overall_best_model\n",
      "  조합 1, 에폭 2: Train Loss=0.0400, Val Loss=0.1697, LR=1.00e-04\n",
      "    에폭 2 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_001_lr_0.0001_r_8_alpha_16_bs_32/epoch_2\n",
      "    조합 내 베스트 모델 갱신 (에폭 2), Val Loss: 0.1697. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_001_lr_0.0001_r_8_alpha_16_bs_32/best_model_in_combo\n",
      "    ✨ 전체 베스트 모델 갱신 (조합 1, 에폭 2), Val Loss: 0.1697. 저장 중...\n",
      "    ✨ 전체 베스트 모델 저장 완료: /workspace/min/pre_train/grid_search_results/overall_best_model\n",
      "  조합 1, 에폭 3: Train Loss=0.0326, Val Loss=0.1538, LR=1.00e-04\n",
      "    에폭 3 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_001_lr_0.0001_r_8_alpha_16_bs_32/epoch_3\n",
      "    조합 내 베스트 모델 갱신 (에폭 3), Val Loss: 0.1538. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_001_lr_0.0001_r_8_alpha_16_bs_32/best_model_in_combo\n",
      "    ✨ 전체 베스트 모델 갱신 (조합 1, 에폭 3), Val Loss: 0.1538. 저장 중...\n",
      "    ✨ 전체 베스트 모델 저장 완료: /workspace/min/pre_train/grid_search_results/overall_best_model\n",
      "  조합 1, 에폭 4: Train Loss=0.0306, Val Loss=0.1641, LR=1.00e-04\n",
      "    에폭 4 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_001_lr_0.0001_r_8_alpha_16_bs_32/epoch_4\n",
      "  조합 1, 에폭 5: Train Loss=0.0265, Val Loss=0.1696, LR=1.00e-04\n",
      "    에폭 5 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_001_lr_0.0001_r_8_alpha_16_bs_32/epoch_5\n",
      "  조합 1, 에폭 6: Train Loss=0.0243, Val Loss=0.2368, LR=1.00e-04\n",
      "    에폭 6 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_001_lr_0.0001_r_8_alpha_16_bs_32/epoch_6\n",
      "  조합 1, 에폭 7: Train Loss=0.0222, Val Loss=0.1943, LR=5.00e-05\n",
      "    에폭 7 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_001_lr_0.0001_r_8_alpha_16_bs_32/epoch_7\n",
      "  조합 1, 에폭 8: Train Loss=0.0194, Val Loss=0.2554, LR=5.00e-05\n",
      "    에폭 8 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_001_lr_0.0001_r_8_alpha_16_bs_32/epoch_8\n",
      "  조합 1, 에폭 9: Train Loss=0.0212, Val Loss=0.1960, LR=5.00e-05\n",
      "    에폭 9 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_001_lr_0.0001_r_8_alpha_16_bs_32/epoch_9\n",
      "  조합 1, 에폭 10: Train Loss=0.0192, Val Loss=0.1497, LR=2.50e-05\n",
      "    에폭 10 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_001_lr_0.0001_r_8_alpha_16_bs_32/epoch_10\n",
      "    조합 내 베스트 모델 갱신 (에폭 10), Val Loss: 0.1497. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_001_lr_0.0001_r_8_alpha_16_bs_32/best_model_in_combo\n",
      "    ✨ 전체 베스트 모델 갱신 (조합 1, 에폭 10), Val Loss: 0.1497. 저장 중...\n",
      "    ✨ 전체 베스트 모델 저장 완료: /workspace/min/pre_train/grid_search_results/overall_best_model\n",
      "--- 그리드 서치 조합 1 완료. 이 조합의 최저 검증 손실: 0.1497 ---\n",
      "조합 1에 사용된 객체들의 메모리 해제를 시도합니다...\n",
      "GPU 캐시를 비웠습니다.\n",
      "가비지 컬렉터가 99개의 객체를 수거했습니다.\n",
      "\n",
      "--- 그리드 서치 조합 2/54 (combo_002_lr_0.0001_r_8_alpha_16_bs_32) 시작 ---\n",
      "현재 하이퍼파라미터: {'learning_rate': 0.0001, 'lora_r': 8, 'lora_alpha': 16, 'batch_size': 32, 'validation_split': 0.2}\n",
      "전체 데이터셋 크기: 25616\n",
      "학습 데이터셋 크기: 20493\n",
      "검증 데이터셋 크기: 5123\n",
      "학습 데이터로더 크기: 641\n",
      "검증 데이터로더 크기: 161\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0839b9c2d1a2468080ba7dbd66e90c52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vocab size: 126464\n",
      "Resizing token embeddings to: 126977\n",
      "New vocab size: 126977\n",
      "QLoRA applied to LLaDA model.\n",
      "Making input embeddings trainable for newly added tokens...\n",
      "Input embeddings are now trainable.\n",
      "trainable params: 524,292,096 || all params: 8,021,876,736 || trainable%: 6.5358\n",
      "\n",
      "옵티마이저를 위한 파라미터 수집 중:\n",
      "옵티마이저를 위한 총 파라미터 그룹 수: 131\n",
      "\n",
      "옵티마이저 및 스케줄러 설정 완료.\n",
      "  조합 2, 에폭 1: Train Loss=0.7161, Val Loss=0.1920, LR=1.00e-04\n",
      "    에폭 1 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_002_lr_0.0001_r_8_alpha_16_bs_32/epoch_1\n",
      "    조합 내 베스트 모델 갱신 (에폭 1), Val Loss: 0.1920. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_002_lr_0.0001_r_8_alpha_16_bs_32/best_model_in_combo\n",
      "  조합 2, 에폭 2: Train Loss=0.0385, Val Loss=0.1624, LR=1.00e-04\n",
      "    에폭 2 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_002_lr_0.0001_r_8_alpha_16_bs_32/epoch_2\n",
      "    조합 내 베스트 모델 갱신 (에폭 2), Val Loss: 0.1624. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_002_lr_0.0001_r_8_alpha_16_bs_32/best_model_in_combo\n",
      "  조합 2, 에폭 3: Train Loss=0.0306, Val Loss=0.1809, LR=1.00e-04\n",
      "    에폭 3 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_002_lr_0.0001_r_8_alpha_16_bs_32/epoch_3\n",
      "  조합 2, 에폭 4: Train Loss=0.0318, Val Loss=0.1692, LR=1.00e-04\n",
      "    에폭 4 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_002_lr_0.0001_r_8_alpha_16_bs_32/epoch_4\n",
      "  조합 2, 에폭 5: Train Loss=0.0263, Val Loss=0.1557, LR=1.00e-04\n",
      "    에폭 5 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_002_lr_0.0001_r_8_alpha_16_bs_32/epoch_5\n",
      "    조합 내 베스트 모델 갱신 (에폭 5), Val Loss: 0.1557. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_002_lr_0.0001_r_8_alpha_16_bs_32/best_model_in_combo\n",
      "  조합 2, 에폭 6: Train Loss=0.0236, Val Loss=0.1645, LR=1.00e-04\n",
      "    에폭 6 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_002_lr_0.0001_r_8_alpha_16_bs_32/epoch_6\n",
      "  조합 2, 에폭 7: Train Loss=0.0264, Val Loss=0.1534, LR=1.00e-04\n",
      "    에폭 7 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_002_lr_0.0001_r_8_alpha_16_bs_32/epoch_7\n",
      "    조합 내 베스트 모델 갱신 (에폭 7), Val Loss: 0.1534. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_002_lr_0.0001_r_8_alpha_16_bs_32/best_model_in_combo\n",
      "  조합 2, 에폭 8: Train Loss=0.0230, Val Loss=0.1698, LR=1.00e-04\n",
      "    에폭 8 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_002_lr_0.0001_r_8_alpha_16_bs_32/epoch_8\n",
      "  조합 2, 에폭 9: Train Loss=0.0238, Val Loss=0.1607, LR=1.00e-04\n",
      "    에폭 9 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_002_lr_0.0001_r_8_alpha_16_bs_32/epoch_9\n",
      "  조합 2, 에폭 10: Train Loss=0.0239, Val Loss=0.1695, LR=1.00e-04\n",
      "    에폭 10 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_002_lr_0.0001_r_8_alpha_16_bs_32/epoch_10\n",
      "--- 그리드 서치 조합 2 완료. 이 조합의 최저 검증 손실: 0.1534 ---\n",
      "조합 2에 사용된 객체들의 메모리 해제를 시도합니다...\n",
      "GPU 캐시를 비웠습니다.\n",
      "가비지 컬렉터가 225개의 객체를 수거했습니다.\n",
      "\n",
      "--- 그리드 서치 조합 3/54 (combo_003_lr_0.0001_r_8_alpha_16_bs_32) 시작 ---\n",
      "현재 하이퍼파라미터: {'learning_rate': 0.0001, 'lora_r': 8, 'lora_alpha': 16, 'batch_size': 32, 'validation_split': 0.3}\n",
      "전체 데이터셋 크기: 25616\n",
      "학습 데이터셋 크기: 17932\n",
      "검증 데이터셋 크기: 7684\n",
      "학습 데이터로더 크기: 561\n",
      "검증 데이터로더 크기: 241\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d3870d79ef546c6bb4eb71d173c9983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vocab size: 126464\n",
      "Resizing token embeddings to: 126977\n",
      "New vocab size: 126977\n",
      "QLoRA applied to LLaDA model.\n",
      "Making input embeddings trainable for newly added tokens...\n",
      "Input embeddings are now trainable.\n",
      "trainable params: 524,292,096 || all params: 8,021,876,736 || trainable%: 6.5358\n",
      "\n",
      "옵티마이저를 위한 파라미터 수집 중:\n",
      "옵티마이저를 위한 총 파라미터 그룹 수: 131\n",
      "\n",
      "옵티마이저 및 스케줄러 설정 완료.\n",
      "  조합 3, 에폭 1: Train Loss=0.8193, Val Loss=0.1702, LR=1.00e-04\n",
      "    에폭 1 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_003_lr_0.0001_r_8_alpha_16_bs_32/epoch_1\n",
      "    조합 내 베스트 모델 갱신 (에폭 1), Val Loss: 0.1702. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_003_lr_0.0001_r_8_alpha_16_bs_32/best_model_in_combo\n",
      "  조합 3, 에폭 2: Train Loss=0.0444, Val Loss=0.1909, LR=1.00e-04\n",
      "    에폭 2 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_003_lr_0.0001_r_8_alpha_16_bs_32/epoch_2\n",
      "  조합 3, 에폭 3: Train Loss=0.0387, Val Loss=0.1690, LR=1.00e-04\n",
      "    에폭 3 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_003_lr_0.0001_r_8_alpha_16_bs_32/epoch_3\n",
      "    조합 내 베스트 모델 갱신 (에폭 3), Val Loss: 0.1690. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_003_lr_0.0001_r_8_alpha_16_bs_32/best_model_in_combo\n",
      "  조합 3, 에폭 4: Train Loss=0.0321, Val Loss=0.1552, LR=1.00e-04\n",
      "    에폭 4 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_003_lr_0.0001_r_8_alpha_16_bs_32/epoch_4\n",
      "    조합 내 베스트 모델 갱신 (에폭 4), Val Loss: 0.1552. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_003_lr_0.0001_r_8_alpha_16_bs_32/best_model_in_combo\n",
      "  조합 3, 에폭 5: Train Loss=0.0309, Val Loss=0.1441, LR=1.00e-04\n",
      "    에폭 5 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_003_lr_0.0001_r_8_alpha_16_bs_32/epoch_5\n",
      "    조합 내 베스트 모델 갱신 (에폭 5), Val Loss: 0.1441. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_003_lr_0.0001_r_8_alpha_16_bs_32/best_model_in_combo\n",
      "    ✨ 전체 베스트 모델 갱신 (조합 3, 에폭 5), Val Loss: 0.1441. 저장 중...\n",
      "    ✨ 전체 베스트 모델 저장 완료: /workspace/min/pre_train/grid_search_results/overall_best_model\n",
      "  조합 3, 에폭 6: Train Loss=0.0318, Val Loss=0.1646, LR=1.00e-04\n",
      "    에폭 6 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_003_lr_0.0001_r_8_alpha_16_bs_32/epoch_6\n",
      "  조합 3, 에폭 7: Train Loss=0.0282, Val Loss=0.1534, LR=1.00e-04\n",
      "    에폭 7 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_003_lr_0.0001_r_8_alpha_16_bs_32/epoch_7\n",
      "  조합 3, 에폭 8: Train Loss=0.0256, Val Loss=0.1575, LR=1.00e-04\n",
      "    에폭 8 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_003_lr_0.0001_r_8_alpha_16_bs_32/epoch_8\n",
      "  조합 3, 에폭 9: Train Loss=0.0209, Val Loss=0.1726, LR=5.00e-05\n",
      "    에폭 9 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_003_lr_0.0001_r_8_alpha_16_bs_32/epoch_9\n",
      "  조합 3, 에폭 10: Train Loss=0.0203, Val Loss=0.1410, LR=5.00e-05\n",
      "    에폭 10 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_003_lr_0.0001_r_8_alpha_16_bs_32/epoch_10\n",
      "    조합 내 베스트 모델 갱신 (에폭 10), Val Loss: 0.1410. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_003_lr_0.0001_r_8_alpha_16_bs_32/best_model_in_combo\n",
      "    ✨ 전체 베스트 모델 갱신 (조합 3, 에폭 10), Val Loss: 0.1410. 저장 중...\n",
      "    ✨ 전체 베스트 모델 저장 완료: /workspace/min/pre_train/grid_search_results/overall_best_model\n",
      "--- 그리드 서치 조합 3 완료. 이 조합의 최저 검증 손실: 0.1410 ---\n",
      "조합 3에 사용된 객체들의 메모리 해제를 시도합니다...\n",
      "GPU 캐시를 비웠습니다.\n",
      "가비지 컬렉터가 99개의 객체를 수거했습니다.\n",
      "\n",
      "--- 그리드 서치 조합 4/54 (combo_004_lr_0.0001_r_8_alpha_16_bs_64) 시작 ---\n",
      "현재 하이퍼파라미터: {'learning_rate': 0.0001, 'lora_r': 8, 'lora_alpha': 16, 'batch_size': 64, 'validation_split': 0.1}\n",
      "전체 데이터셋 크기: 25616\n",
      "학습 데이터셋 크기: 23055\n",
      "검증 데이터셋 크기: 2561\n",
      "학습 데이터로더 크기: 361\n",
      "검증 데이터로더 크기: 41\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4d0c4cc9cc453e8585e655214b2387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vocab size: 126464\n",
      "Resizing token embeddings to: 126977\n",
      "New vocab size: 126977\n",
      "QLoRA applied to LLaDA model.\n",
      "Making input embeddings trainable for newly added tokens...\n",
      "Input embeddings are now trainable.\n",
      "trainable params: 524,292,096 || all params: 8,021,876,736 || trainable%: 6.5358\n",
      "\n",
      "옵티마이저를 위한 파라미터 수집 중:\n",
      "옵티마이저를 위한 총 파라미터 그룹 수: 131\n",
      "\n",
      "옵티마이저 및 스케줄러 설정 완료.\n",
      "  조합 4, 에폭 1: Train Loss=1.0999, Val Loss=0.1538, LR=1.00e-04\n",
      "    에폭 1 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_004_lr_0.0001_r_8_alpha_16_bs_64/epoch_1\n",
      "    조합 내 베스트 모델 갱신 (에폭 1), Val Loss: 0.1538. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_004_lr_0.0001_r_8_alpha_16_bs_64/best_model_in_combo\n",
      "  조합 4, 에폭 2: Train Loss=0.0342, Val Loss=0.1912, LR=1.00e-04\n",
      "    에폭 2 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_004_lr_0.0001_r_8_alpha_16_bs_64/epoch_2\n",
      "  조합 4, 에폭 3: Train Loss=0.0322, Val Loss=0.1444, LR=1.00e-04\n",
      "    에폭 3 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_004_lr_0.0001_r_8_alpha_16_bs_64/epoch_3\n",
      "    조합 내 베스트 모델 갱신 (에폭 3), Val Loss: 0.1444. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_004_lr_0.0001_r_8_alpha_16_bs_64/best_model_in_combo\n",
      "  조합 4, 에폭 4: Train Loss=0.0275, Val Loss=0.1510, LR=1.00e-04\n",
      "    에폭 4 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_004_lr_0.0001_r_8_alpha_16_bs_64/epoch_4\n",
      "  조합 4, 에폭 5: Train Loss=0.0236, Val Loss=0.1507, LR=1.00e-04\n",
      "    에폭 5 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_004_lr_0.0001_r_8_alpha_16_bs_64/epoch_5\n",
      "  조합 4, 에폭 6: Train Loss=0.0253, Val Loss=0.1272, LR=1.00e-04\n",
      "    에폭 6 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_004_lr_0.0001_r_8_alpha_16_bs_64/epoch_6\n",
      "    조합 내 베스트 모델 갱신 (에폭 6), Val Loss: 0.1272. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_004_lr_0.0001_r_8_alpha_16_bs_64/best_model_in_combo\n",
      "    ✨ 전체 베스트 모델 갱신 (조합 4, 에폭 6), Val Loss: 0.1272. 저장 중...\n",
      "    ✨ 전체 베스트 모델 저장 완료: /workspace/min/pre_train/grid_search_results/overall_best_model\n",
      "  조합 4, 에폭 7: Train Loss=0.0256, Val Loss=0.1639, LR=1.00e-04\n",
      "    에폭 7 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_004_lr_0.0001_r_8_alpha_16_bs_64/epoch_7\n",
      "  조합 4, 에폭 8: Train Loss=0.0256, Val Loss=0.1501, LR=1.00e-04\n",
      "    에폭 8 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_004_lr_0.0001_r_8_alpha_16_bs_64/epoch_8\n",
      "  조합 4, 에폭 9: Train Loss=0.0209, Val Loss=0.1552, LR=1.00e-04\n",
      "    에폭 9 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_004_lr_0.0001_r_8_alpha_16_bs_64/epoch_9\n",
      "  조합 4, 에폭 10: Train Loss=0.0207, Val Loss=0.1637, LR=5.00e-05\n",
      "    에폭 10 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_004_lr_0.0001_r_8_alpha_16_bs_64/epoch_10\n",
      "--- 그리드 서치 조합 4 완료. 이 조합의 최저 검증 손실: 0.1272 ---\n",
      "조합 4에 사용된 객체들의 메모리 해제를 시도합니다...\n",
      "GPU 캐시를 비웠습니다.\n",
      "가비지 컬렉터가 225개의 객체를 수거했습니다.\n",
      "\n",
      "--- 그리드 서치 조합 5/54 (combo_005_lr_0.0001_r_8_alpha_16_bs_64) 시작 ---\n",
      "현재 하이퍼파라미터: {'learning_rate': 0.0001, 'lora_r': 8, 'lora_alpha': 16, 'batch_size': 64, 'validation_split': 0.2}\n",
      "전체 데이터셋 크기: 25616\n",
      "학습 데이터셋 크기: 20493\n",
      "검증 데이터셋 크기: 5123\n",
      "학습 데이터로더 크기: 321\n",
      "검증 데이터로더 크기: 81\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "436ad1bed31d46fd8c6c66562a263e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vocab size: 126464\n",
      "Resizing token embeddings to: 126977\n",
      "New vocab size: 126977\n",
      "QLoRA applied to LLaDA model.\n",
      "Making input embeddings trainable for newly added tokens...\n",
      "Input embeddings are now trainable.\n",
      "trainable params: 524,292,096 || all params: 8,021,876,736 || trainable%: 6.5358\n",
      "\n",
      "옵티마이저를 위한 파라미터 수집 중:\n",
      "옵티마이저를 위한 총 파라미터 그룹 수: 131\n",
      "\n",
      "옵티마이저 및 스케줄러 설정 완료.\n",
      "  조합 5, 에폭 1: Train Loss=1.2485, Val Loss=0.1879, LR=1.00e-04\n",
      "    에폭 1 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_005_lr_0.0001_r_8_alpha_16_bs_64/epoch_1\n",
      "    조합 내 베스트 모델 갱신 (에폭 1), Val Loss: 0.1879. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_005_lr_0.0001_r_8_alpha_16_bs_64/best_model_in_combo\n",
      "  조합 5, 에폭 2: Train Loss=0.0396, Val Loss=0.1993, LR=1.00e-04\n",
      "    에폭 2 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_005_lr_0.0001_r_8_alpha_16_bs_64/epoch_2\n",
      "  조합 5, 에폭 3: Train Loss=0.0347, Val Loss=0.1595, LR=1.00e-04\n",
      "    에폭 3 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_005_lr_0.0001_r_8_alpha_16_bs_64/epoch_3\n",
      "    조합 내 베스트 모델 갱신 (에폭 3), Val Loss: 0.1595. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_005_lr_0.0001_r_8_alpha_16_bs_64/best_model_in_combo\n",
      "  조합 5, 에폭 4: Train Loss=0.0274, Val Loss=0.1799, LR=1.00e-04\n",
      "    에폭 4 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_005_lr_0.0001_r_8_alpha_16_bs_64/epoch_4\n",
      "  조합 5, 에폭 5: Train Loss=0.0248, Val Loss=0.2119, LR=1.00e-04\n",
      "    에폭 5 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_005_lr_0.0001_r_8_alpha_16_bs_64/epoch_5\n",
      "  조합 5, 에폭 6: Train Loss=0.0227, Val Loss=0.1727, LR=1.00e-04\n",
      "    에폭 6 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_005_lr_0.0001_r_8_alpha_16_bs_64/epoch_6\n",
      "  조합 5, 에폭 7: Train Loss=0.0222, Val Loss=0.2296, LR=5.00e-05\n",
      "    에폭 7 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_005_lr_0.0001_r_8_alpha_16_bs_64/epoch_7\n",
      "  조합 5, 에폭 8: Train Loss=0.0214, Val Loss=0.1915, LR=5.00e-05\n",
      "    에폭 8 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_005_lr_0.0001_r_8_alpha_16_bs_64/epoch_8\n",
      "  조합 5, 에폭 9: Train Loss=0.0214, Val Loss=0.1958, LR=5.00e-05\n",
      "    에폭 9 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_005_lr_0.0001_r_8_alpha_16_bs_64/epoch_9\n",
      "  조합 5, 에폭 10: Train Loss=0.0225, Val Loss=0.2414, LR=2.50e-05\n",
      "    에폭 10 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_005_lr_0.0001_r_8_alpha_16_bs_64/epoch_10\n",
      "--- 그리드 서치 조합 5 완료. 이 조합의 최저 검증 손실: 0.1595 ---\n",
      "조합 5에 사용된 객체들의 메모리 해제를 시도합니다...\n",
      "GPU 캐시를 비웠습니다.\n",
      "가비지 컬렉터가 225개의 객체를 수거했습니다.\n",
      "\n",
      "--- 그리드 서치 조합 6/54 (combo_006_lr_0.0001_r_8_alpha_16_bs_64) 시작 ---\n",
      "현재 하이퍼파라미터: {'learning_rate': 0.0001, 'lora_r': 8, 'lora_alpha': 16, 'batch_size': 64, 'validation_split': 0.3}\n",
      "전체 데이터셋 크기: 25616\n",
      "학습 데이터셋 크기: 17932\n",
      "검증 데이터셋 크기: 7684\n",
      "학습 데이터로더 크기: 281\n",
      "검증 데이터로더 크기: 121\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ff7a52a41a34a0aa29bc4e0da94e1fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vocab size: 126464\n",
      "Resizing token embeddings to: 126977\n",
      "New vocab size: 126977\n",
      "QLoRA applied to LLaDA model.\n",
      "Making input embeddings trainable for newly added tokens...\n",
      "Input embeddings are now trainable.\n",
      "trainable params: 524,292,096 || all params: 8,021,876,736 || trainable%: 6.5358\n",
      "\n",
      "옵티마이저를 위한 파라미터 수집 중:\n",
      "옵티마이저를 위한 총 파라미터 그룹 수: 131\n",
      "\n",
      "옵티마이저 및 스케줄러 설정 완료.\n",
      "  조합 6, 에폭 1: Train Loss=1.3841, Val Loss=0.1912, LR=1.00e-04\n",
      "    에폭 1 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_006_lr_0.0001_r_8_alpha_16_bs_64/epoch_1\n",
      "    조합 내 베스트 모델 갱신 (에폭 1), Val Loss: 0.1912. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_006_lr_0.0001_r_8_alpha_16_bs_64/best_model_in_combo\n",
      "  조합 6, 에폭 2: Train Loss=0.0472, Val Loss=0.1979, LR=1.00e-04\n",
      "    에폭 2 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_006_lr_0.0001_r_8_alpha_16_bs_64/epoch_2\n",
      "  조합 6, 에폭 3: Train Loss=0.0292, Val Loss=0.1488, LR=1.00e-04\n",
      "    에폭 3 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_006_lr_0.0001_r_8_alpha_16_bs_64/epoch_3\n",
      "    조합 내 베스트 모델 갱신 (에폭 3), Val Loss: 0.1488. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_006_lr_0.0001_r_8_alpha_16_bs_64/best_model_in_combo\n",
      "  조합 6, 에폭 4: Train Loss=0.0276, Val Loss=0.1682, LR=1.00e-04\n",
      "    에폭 4 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_006_lr_0.0001_r_8_alpha_16_bs_64/epoch_4\n",
      "  조합 6, 에폭 5: Train Loss=0.0239, Val Loss=0.1728, LR=1.00e-04\n",
      "    에폭 5 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_006_lr_0.0001_r_8_alpha_16_bs_64/epoch_5\n",
      "  조합 6, 에폭 6: Train Loss=0.0248, Val Loss=0.1316, LR=1.00e-04\n",
      "    에폭 6 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_006_lr_0.0001_r_8_alpha_16_bs_64/epoch_6\n",
      "    조합 내 베스트 모델 갱신 (에폭 6), Val Loss: 0.1316. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_006_lr_0.0001_r_8_alpha_16_bs_64/best_model_in_combo\n",
      "  조합 6, 에폭 7: Train Loss=0.0265, Val Loss=0.1558, LR=1.00e-04\n",
      "    에폭 7 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_006_lr_0.0001_r_8_alpha_16_bs_64/epoch_7\n",
      "  조합 6, 에폭 8: Train Loss=0.0238, Val Loss=0.1598, LR=1.00e-04\n",
      "    에폭 8 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_006_lr_0.0001_r_8_alpha_16_bs_64/epoch_8\n",
      "  조합 6, 에폭 9: Train Loss=0.0225, Val Loss=0.1379, LR=1.00e-04\n",
      "    에폭 9 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_006_lr_0.0001_r_8_alpha_16_bs_64/epoch_9\n",
      "  조합 6, 에폭 10: Train Loss=0.0222, Val Loss=0.1394, LR=5.00e-05\n",
      "    에폭 10 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_006_lr_0.0001_r_8_alpha_16_bs_64/epoch_10\n",
      "--- 그리드 서치 조합 6 완료. 이 조합의 최저 검증 손실: 0.1316 ---\n",
      "조합 6에 사용된 객체들의 메모리 해제를 시도합니다...\n",
      "GPU 캐시를 비웠습니다.\n",
      "가비지 컬렉터가 225개의 객체를 수거했습니다.\n",
      "\n",
      "--- 그리드 서치 조합 7/54 (combo_007_lr_0.0001_r_8_alpha_32_bs_32) 시작 ---\n",
      "현재 하이퍼파라미터: {'learning_rate': 0.0001, 'lora_r': 8, 'lora_alpha': 32, 'batch_size': 32, 'validation_split': 0.1}\n",
      "전체 데이터셋 크기: 25616\n",
      "학습 데이터셋 크기: 23055\n",
      "검증 데이터셋 크기: 2561\n",
      "학습 데이터로더 크기: 721\n",
      "검증 데이터로더 크기: 81\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7838c9eb0be45c2b2f45af15843abea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vocab size: 126464\n",
      "Resizing token embeddings to: 126977\n",
      "New vocab size: 126977\n",
      "QLoRA applied to LLaDA model.\n",
      "Making input embeddings trainable for newly added tokens...\n",
      "Input embeddings are now trainable.\n",
      "trainable params: 524,292,096 || all params: 8,021,876,736 || trainable%: 6.5358\n",
      "\n",
      "옵티마이저를 위한 파라미터 수집 중:\n",
      "옵티마이저를 위한 총 파라미터 그룹 수: 131\n",
      "\n",
      "옵티마이저 및 스케줄러 설정 완료.\n",
      "  조합 7, 에폭 1: Train Loss=0.5643, Val Loss=0.1925, LR=1.00e-04\n",
      "    에폭 1 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_007_lr_0.0001_r_8_alpha_32_bs_32/epoch_1\n",
      "    조합 내 베스트 모델 갱신 (에폭 1), Val Loss: 0.1925. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_007_lr_0.0001_r_8_alpha_32_bs_32/best_model_in_combo\n",
      "  조합 7, 에폭 2: Train Loss=0.0454, Val Loss=0.1356, LR=1.00e-04\n",
      "    에폭 2 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_007_lr_0.0001_r_8_alpha_32_bs_32/epoch_2\n",
      "    조합 내 베스트 모델 갱신 (에폭 2), Val Loss: 0.1356. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_007_lr_0.0001_r_8_alpha_32_bs_32/best_model_in_combo\n",
      "  조합 7, 에폭 3: Train Loss=0.0377, Val Loss=0.1294, LR=1.00e-04\n",
      "    에폭 3 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_007_lr_0.0001_r_8_alpha_32_bs_32/epoch_3\n",
      "    조합 내 베스트 모델 갱신 (에폭 3), Val Loss: 0.1294. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_007_lr_0.0001_r_8_alpha_32_bs_32/best_model_in_combo\n",
      "  조합 7, 에폭 4: Train Loss=0.0336, Val Loss=0.1157, LR=1.00e-04\n",
      "    에폭 4 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_007_lr_0.0001_r_8_alpha_32_bs_32/epoch_4\n",
      "    조합 내 베스트 모델 갱신 (에폭 4), Val Loss: 0.1157. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_007_lr_0.0001_r_8_alpha_32_bs_32/best_model_in_combo\n",
      "    ✨ 전체 베스트 모델 갱신 (조합 7, 에폭 4), Val Loss: 0.1157. 저장 중...\n",
      "    ✨ 전체 베스트 모델 저장 완료: /workspace/min/pre_train/grid_search_results/overall_best_model\n",
      "  조합 7, 에폭 5: Train Loss=0.0293, Val Loss=0.1338, LR=1.00e-04\n",
      "    에폭 5 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_007_lr_0.0001_r_8_alpha_32_bs_32/epoch_5\n",
      "  조합 7, 에폭 6: Train Loss=0.0263, Val Loss=0.2052, LR=1.00e-04\n",
      "    에폭 6 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_007_lr_0.0001_r_8_alpha_32_bs_32/epoch_6\n",
      "  조합 7, 에폭 7: Train Loss=0.0268, Val Loss=0.1630, LR=1.00e-04\n",
      "    에폭 7 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_007_lr_0.0001_r_8_alpha_32_bs_32/epoch_7\n",
      "  조합 7, 에폭 8: Train Loss=0.0196, Val Loss=0.1918, LR=5.00e-05\n",
      "    에폭 8 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_007_lr_0.0001_r_8_alpha_32_bs_32/epoch_8\n",
      "  조합 7, 에폭 9: Train Loss=0.0243, Val Loss=0.1650, LR=5.00e-05\n",
      "    에폭 9 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_007_lr_0.0001_r_8_alpha_32_bs_32/epoch_9\n",
      "  조합 7, 에폭 10: Train Loss=0.0214, Val Loss=0.1258, LR=5.00e-05\n",
      "    에폭 10 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_007_lr_0.0001_r_8_alpha_32_bs_32/epoch_10\n",
      "--- 그리드 서치 조합 7 완료. 이 조합의 최저 검증 손실: 0.1157 ---\n",
      "조합 7에 사용된 객체들의 메모리 해제를 시도합니다...\n",
      "GPU 캐시를 비웠습니다.\n",
      "가비지 컬렉터가 225개의 객체를 수거했습니다.\n",
      "\n",
      "--- 그리드 서치 조합 8/54 (combo_008_lr_0.0001_r_8_alpha_32_bs_32) 시작 ---\n",
      "현재 하이퍼파라미터: {'learning_rate': 0.0001, 'lora_r': 8, 'lora_alpha': 32, 'batch_size': 32, 'validation_split': 0.2}\n",
      "전체 데이터셋 크기: 25616\n",
      "학습 데이터셋 크기: 20493\n",
      "검증 데이터셋 크기: 5123\n",
      "학습 데이터로더 크기: 641\n",
      "검증 데이터로더 크기: 161\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b38549c70844eb5a2fc0014edfcea96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vocab size: 126464\n",
      "Resizing token embeddings to: 126977\n",
      "New vocab size: 126977\n",
      "QLoRA applied to LLaDA model.\n",
      "Making input embeddings trainable for newly added tokens...\n",
      "Input embeddings are now trainable.\n",
      "trainable params: 524,292,096 || all params: 8,021,876,736 || trainable%: 6.5358\n",
      "\n",
      "옵티마이저를 위한 파라미터 수집 중:\n",
      "옵티마이저를 위한 총 파라미터 그룹 수: 131\n",
      "\n",
      "옵티마이저 및 스케줄러 설정 완료.\n",
      "  조합 8, 에폭 1: Train Loss=0.6199, Val Loss=0.1778, LR=1.00e-04\n",
      "    에폭 1 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_008_lr_0.0001_r_8_alpha_32_bs_32/epoch_1\n",
      "    조합 내 베스트 모델 갱신 (에폭 1), Val Loss: 0.1778. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_008_lr_0.0001_r_8_alpha_32_bs_32/best_model_in_combo\n",
      "  조합 8, 에폭 2: Train Loss=0.0373, Val Loss=0.1550, LR=1.00e-04\n",
      "    에폭 2 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_008_lr_0.0001_r_8_alpha_32_bs_32/epoch_2\n",
      "    조합 내 베스트 모델 갱신 (에폭 2), Val Loss: 0.1550. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_008_lr_0.0001_r_8_alpha_32_bs_32/best_model_in_combo\n",
      "  조합 8, 에폭 3: Train Loss=0.0375, Val Loss=0.1552, LR=1.00e-04\n",
      "    에폭 3 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_008_lr_0.0001_r_8_alpha_32_bs_32/epoch_3\n",
      "  조합 8, 에폭 4: Train Loss=0.0346, Val Loss=0.1618, LR=1.00e-04\n",
      "    에폭 4 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_008_lr_0.0001_r_8_alpha_32_bs_32/epoch_4\n",
      "  조합 8, 에폭 5: Train Loss=0.0309, Val Loss=0.1586, LR=1.00e-04\n",
      "    에폭 5 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_008_lr_0.0001_r_8_alpha_32_bs_32/epoch_5\n",
      "  조합 8, 에폭 6: Train Loss=0.0240, Val Loss=0.1570, LR=5.00e-05\n",
      "    에폭 6 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_008_lr_0.0001_r_8_alpha_32_bs_32/epoch_6\n",
      "  조합 8, 에폭 7: Train Loss=0.0236, Val Loss=0.1494, LR=5.00e-05\n",
      "    에폭 7 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_008_lr_0.0001_r_8_alpha_32_bs_32/epoch_7\n",
      "    조합 내 베스트 모델 갱신 (에폭 7), Val Loss: 0.1494. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_008_lr_0.0001_r_8_alpha_32_bs_32/best_model_in_combo\n",
      "  조합 8, 에폭 8: Train Loss=0.0241, Val Loss=0.1652, LR=5.00e-05\n",
      "    에폭 8 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_008_lr_0.0001_r_8_alpha_32_bs_32/epoch_8\n",
      "  조합 8, 에폭 9: Train Loss=0.0231, Val Loss=0.1512, LR=5.00e-05\n",
      "    에폭 9 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_008_lr_0.0001_r_8_alpha_32_bs_32/epoch_9\n",
      "  조합 8, 에폭 10: Train Loss=0.0228, Val Loss=0.1702, LR=5.00e-05\n",
      "    에폭 10 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_008_lr_0.0001_r_8_alpha_32_bs_32/epoch_10\n",
      "--- 그리드 서치 조합 8 완료. 이 조합의 최저 검증 손실: 0.1494 ---\n",
      "조합 8에 사용된 객체들의 메모리 해제를 시도합니다...\n",
      "GPU 캐시를 비웠습니다.\n",
      "가비지 컬렉터가 225개의 객체를 수거했습니다.\n",
      "\n",
      "--- 그리드 서치 조합 9/54 (combo_009_lr_0.0001_r_8_alpha_32_bs_32) 시작 ---\n",
      "현재 하이퍼파라미터: {'learning_rate': 0.0001, 'lora_r': 8, 'lora_alpha': 32, 'batch_size': 32, 'validation_split': 0.3}\n",
      "전체 데이터셋 크기: 25616\n",
      "학습 데이터셋 크기: 17932\n",
      "검증 데이터셋 크기: 7684\n",
      "학습 데이터로더 크기: 561\n",
      "검증 데이터로더 크기: 241\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "228a3f8599b84ab78f9eedf3e14be549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vocab size: 126464\n",
      "Resizing token embeddings to: 126977\n",
      "New vocab size: 126977\n",
      "QLoRA applied to LLaDA model.\n",
      "Making input embeddings trainable for newly added tokens...\n",
      "Input embeddings are now trainable.\n",
      "trainable params: 524,292,096 || all params: 8,021,876,736 || trainable%: 6.5358\n",
      "\n",
      "옵티마이저를 위한 파라미터 수집 중:\n",
      "옵티마이저를 위한 총 파라미터 그룹 수: 131\n",
      "\n",
      "옵티마이저 및 스케줄러 설정 완료.\n",
      "  조합 9, 에폭 1: Train Loss=0.7188, Val Loss=0.1733, LR=1.00e-04\n",
      "    에폭 1 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_009_lr_0.0001_r_8_alpha_32_bs_32/epoch_1\n",
      "    조합 내 베스트 모델 갱신 (에폭 1), Val Loss: 0.1733. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_009_lr_0.0001_r_8_alpha_32_bs_32/best_model_in_combo\n",
      "  조합 9, 에폭 2: Train Loss=0.0436, Val Loss=0.1920, LR=1.00e-04\n",
      "    에폭 2 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_009_lr_0.0001_r_8_alpha_32_bs_32/epoch_2\n",
      "  조합 9, 에폭 3: Train Loss=0.0389, Val Loss=0.1648, LR=1.00e-04\n",
      "    에폭 3 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_009_lr_0.0001_r_8_alpha_32_bs_32/epoch_3\n",
      "    조합 내 베스트 모델 갱신 (에폭 3), Val Loss: 0.1648. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_009_lr_0.0001_r_8_alpha_32_bs_32/best_model_in_combo\n",
      "  조합 9, 에폭 4: Train Loss=0.0348, Val Loss=0.1588, LR=1.00e-04\n",
      "    에폭 4 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_009_lr_0.0001_r_8_alpha_32_bs_32/epoch_4\n",
      "    조합 내 베스트 모델 갱신 (에폭 4), Val Loss: 0.1588. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_009_lr_0.0001_r_8_alpha_32_bs_32/best_model_in_combo\n",
      "  조합 9, 에폭 5: Train Loss=0.0328, Val Loss=0.1472, LR=1.00e-04\n",
      "    에폭 5 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_009_lr_0.0001_r_8_alpha_32_bs_32/epoch_5\n",
      "    조합 내 베스트 모델 갱신 (에폭 5), Val Loss: 0.1472. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_009_lr_0.0001_r_8_alpha_32_bs_32/best_model_in_combo\n",
      "  조합 9, 에폭 6: Train Loss=0.0349, Val Loss=0.1661, LR=1.00e-04\n",
      "    에폭 6 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_009_lr_0.0001_r_8_alpha_32_bs_32/epoch_6\n",
      "  조합 9, 에폭 7: Train Loss=0.0281, Val Loss=0.1599, LR=1.00e-04\n",
      "    에폭 7 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_009_lr_0.0001_r_8_alpha_32_bs_32/epoch_7\n",
      "  조합 9, 에폭 8: Train Loss=0.0263, Val Loss=0.1628, LR=1.00e-04\n",
      "    에폭 8 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_009_lr_0.0001_r_8_alpha_32_bs_32/epoch_8\n",
      "  조합 9, 에폭 9: Train Loss=0.0214, Val Loss=0.1839, LR=5.00e-05\n",
      "    에폭 9 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_009_lr_0.0001_r_8_alpha_32_bs_32/epoch_9\n",
      "  조합 9, 에폭 10: Train Loss=0.0210, Val Loss=0.1469, LR=5.00e-05\n",
      "    에폭 10 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_009_lr_0.0001_r_8_alpha_32_bs_32/epoch_10\n",
      "    조합 내 베스트 모델 갱신 (에폭 10), Val Loss: 0.1469. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_009_lr_0.0001_r_8_alpha_32_bs_32/best_model_in_combo\n",
      "--- 그리드 서치 조합 9 완료. 이 조합의 최저 검증 손실: 0.1469 ---\n",
      "조합 9에 사용된 객체들의 메모리 해제를 시도합니다...\n",
      "GPU 캐시를 비웠습니다.\n",
      "가비지 컬렉터가 101개의 객체를 수거했습니다.\n",
      "\n",
      "--- 그리드 서치 조합 10/54 (combo_010_lr_0.0001_r_8_alpha_32_bs_64) 시작 ---\n",
      "현재 하이퍼파라미터: {'learning_rate': 0.0001, 'lora_r': 8, 'lora_alpha': 32, 'batch_size': 64, 'validation_split': 0.1}\n",
      "전체 데이터셋 크기: 25616\n",
      "학습 데이터셋 크기: 23055\n",
      "검증 데이터셋 크기: 2561\n",
      "학습 데이터로더 크기: 361\n",
      "검증 데이터로더 크기: 41\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb6e8b8cc931484d9baa1cb2ab3e451c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vocab size: 126464\n",
      "Resizing token embeddings to: 126977\n",
      "New vocab size: 126977\n",
      "QLoRA applied to LLaDA model.\n",
      "Making input embeddings trainable for newly added tokens...\n",
      "Input embeddings are now trainable.\n",
      "trainable params: 524,292,096 || all params: 8,021,876,736 || trainable%: 6.5358\n",
      "\n",
      "옵티마이저를 위한 파라미터 수집 중:\n",
      "옵티마이저를 위한 총 파라미터 그룹 수: 131\n",
      "\n",
      "옵티마이저 및 스케줄러 설정 완료.\n",
      "  조합 10, 에폭 1: Train Loss=0.9740, Val Loss=0.1622, LR=1.00e-04\n",
      "    에폭 1 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_010_lr_0.0001_r_8_alpha_32_bs_64/epoch_1\n",
      "    조합 내 베스트 모델 갱신 (에폭 1), Val Loss: 0.1622. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_010_lr_0.0001_r_8_alpha_32_bs_64/best_model_in_combo\n",
      "  조합 10, 에폭 2: Train Loss=0.0364, Val Loss=0.1925, LR=1.00e-04\n",
      "    에폭 2 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_010_lr_0.0001_r_8_alpha_32_bs_64/epoch_2\n",
      "  조합 10, 에폭 3: Train Loss=0.0350, Val Loss=0.1419, LR=1.00e-04\n",
      "    에폭 3 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_010_lr_0.0001_r_8_alpha_32_bs_64/epoch_3\n",
      "    조합 내 베스트 모델 갱신 (에폭 3), Val Loss: 0.1419. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_010_lr_0.0001_r_8_alpha_32_bs_64/best_model_in_combo\n",
      "  조합 10, 에폭 4: Train Loss=0.0284, Val Loss=0.1668, LR=1.00e-04\n",
      "    에폭 4 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_010_lr_0.0001_r_8_alpha_32_bs_64/epoch_4\n",
      "  조합 10, 에폭 5: Train Loss=0.0244, Val Loss=0.1487, LR=1.00e-04\n",
      "    에폭 5 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_010_lr_0.0001_r_8_alpha_32_bs_64/epoch_5\n",
      "  조합 10, 에폭 6: Train Loss=0.0253, Val Loss=0.1609, LR=1.00e-04\n",
      "    에폭 6 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_010_lr_0.0001_r_8_alpha_32_bs_64/epoch_6\n",
      "  조합 10, 에폭 7: Train Loss=0.0242, Val Loss=0.2074, LR=5.00e-05\n",
      "    에폭 7 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_010_lr_0.0001_r_8_alpha_32_bs_64/epoch_7\n",
      "  조합 10, 에폭 8: Train Loss=0.0230, Val Loss=0.1947, LR=5.00e-05\n",
      "    에폭 8 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_010_lr_0.0001_r_8_alpha_32_bs_64/epoch_8\n",
      "  조합 10, 에폭 9: Train Loss=0.0197, Val Loss=0.1928, LR=5.00e-05\n",
      "    에폭 9 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_010_lr_0.0001_r_8_alpha_32_bs_64/epoch_9\n",
      "  조합 10, 에폭 10: Train Loss=0.0210, Val Loss=0.1951, LR=2.50e-05\n",
      "    에폭 10 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_010_lr_0.0001_r_8_alpha_32_bs_64/epoch_10\n",
      "--- 그리드 서치 조합 10 완료. 이 조합의 최저 검증 손실: 0.1419 ---\n",
      "조합 10에 사용된 객체들의 메모리 해제를 시도합니다...\n",
      "GPU 캐시를 비웠습니다.\n",
      "가비지 컬렉터가 225개의 객체를 수거했습니다.\n",
      "\n",
      "--- 그리드 서치 조합 11/54 (combo_011_lr_0.0001_r_8_alpha_32_bs_64) 시작 ---\n",
      "현재 하이퍼파라미터: {'learning_rate': 0.0001, 'lora_r': 8, 'lora_alpha': 32, 'batch_size': 64, 'validation_split': 0.2}\n",
      "전체 데이터셋 크기: 25616\n",
      "학습 데이터셋 크기: 20493\n",
      "검증 데이터셋 크기: 5123\n",
      "학습 데이터로더 크기: 321\n",
      "검증 데이터로더 크기: 81\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ada1f4bc3e42af9737622f4a9db1e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vocab size: 126464\n",
      "Resizing token embeddings to: 126977\n",
      "New vocab size: 126977\n",
      "QLoRA applied to LLaDA model.\n",
      "Making input embeddings trainable for newly added tokens...\n",
      "Input embeddings are now trainable.\n",
      "trainable params: 524,292,096 || all params: 8,021,876,736 || trainable%: 6.5358\n",
      "\n",
      "옵티마이저를 위한 파라미터 수집 중:\n",
      "옵티마이저를 위한 총 파라미터 그룹 수: 131\n",
      "\n",
      "옵티마이저 및 스케줄러 설정 완료.\n",
      "  조합 11, 에폭 1: Train Loss=1.0999, Val Loss=0.1865, LR=1.00e-04\n",
      "    에폭 1 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_011_lr_0.0001_r_8_alpha_32_bs_64/epoch_1\n",
      "    조합 내 베스트 모델 갱신 (에폭 1), Val Loss: 0.1865. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_011_lr_0.0001_r_8_alpha_32_bs_64/best_model_in_combo\n",
      "  조합 11, 에폭 2: Train Loss=0.0412, Val Loss=0.1846, LR=1.00e-04\n",
      "    에폭 2 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_011_lr_0.0001_r_8_alpha_32_bs_64/epoch_2\n",
      "    조합 내 베스트 모델 갱신 (에폭 2), Val Loss: 0.1846. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_011_lr_0.0001_r_8_alpha_32_bs_64/best_model_in_combo\n",
      "  조합 11, 에폭 3: Train Loss=0.0400, Val Loss=0.1293, LR=1.00e-04\n",
      "    에폭 3 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_011_lr_0.0001_r_8_alpha_32_bs_64/epoch_3\n",
      "    조합 내 베스트 모델 갱신 (에폭 3), Val Loss: 0.1293. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_011_lr_0.0001_r_8_alpha_32_bs_64/best_model_in_combo\n",
      "  조합 11, 에폭 4: Train Loss=0.0321, Val Loss=0.1495, LR=1.00e-04\n",
      "    에폭 4 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_011_lr_0.0001_r_8_alpha_32_bs_64/epoch_4\n",
      "  조합 11, 에폭 5: Train Loss=0.0273, Val Loss=0.1734, LR=1.00e-04\n",
      "    에폭 5 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_011_lr_0.0001_r_8_alpha_32_bs_64/epoch_5\n",
      "  조합 11, 에폭 6: Train Loss=0.0233, Val Loss=0.1552, LR=1.00e-04\n",
      "    에폭 6 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_011_lr_0.0001_r_8_alpha_32_bs_64/epoch_6\n",
      "  조합 11, 에폭 7: Train Loss=0.0224, Val Loss=0.1792, LR=5.00e-05\n",
      "    에폭 7 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_011_lr_0.0001_r_8_alpha_32_bs_64/epoch_7\n",
      "  조합 11, 에폭 8: Train Loss=0.0217, Val Loss=0.1598, LR=5.00e-05\n",
      "    에폭 8 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_011_lr_0.0001_r_8_alpha_32_bs_64/epoch_8\n",
      "  조합 11, 에폭 9: Train Loss=0.0215, Val Loss=0.1604, LR=5.00e-05\n",
      "    에폭 9 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_011_lr_0.0001_r_8_alpha_32_bs_64/epoch_9\n",
      "  조합 11, 에폭 10: Train Loss=0.0221, Val Loss=0.1846, LR=2.50e-05\n",
      "    에폭 10 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_011_lr_0.0001_r_8_alpha_32_bs_64/epoch_10\n",
      "--- 그리드 서치 조합 11 완료. 이 조합의 최저 검증 손실: 0.1293 ---\n",
      "조합 11에 사용된 객체들의 메모리 해제를 시도합니다...\n",
      "GPU 캐시를 비웠습니다.\n",
      "가비지 컬렉터가 223개의 객체를 수거했습니다.\n",
      "\n",
      "--- 그리드 서치 조합 12/54 (combo_012_lr_0.0001_r_8_alpha_32_bs_64) 시작 ---\n",
      "현재 하이퍼파라미터: {'learning_rate': 0.0001, 'lora_r': 8, 'lora_alpha': 32, 'batch_size': 64, 'validation_split': 0.3}\n",
      "전체 데이터셋 크기: 25616\n",
      "학습 데이터셋 크기: 17932\n",
      "검증 데이터셋 크기: 7684\n",
      "학습 데이터로더 크기: 281\n",
      "검증 데이터로더 크기: 121\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f1656982b8b46f3bdffc193bcb4474d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vocab size: 126464\n",
      "Resizing token embeddings to: 126977\n",
      "New vocab size: 126977\n",
      "QLoRA applied to LLaDA model.\n",
      "Making input embeddings trainable for newly added tokens...\n",
      "Input embeddings are now trainable.\n",
      "trainable params: 524,292,096 || all params: 8,021,876,736 || trainable%: 6.5358\n",
      "\n",
      "옵티마이저를 위한 파라미터 수집 중:\n",
      "옵티마이저를 위한 총 파라미터 그룹 수: 131\n",
      "\n",
      "옵티마이저 및 스케줄러 설정 완료.\n",
      "  조합 12, 에폭 1: Train Loss=1.2320, Val Loss=0.1917, LR=1.00e-04\n",
      "    에폭 1 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_012_lr_0.0001_r_8_alpha_32_bs_64/epoch_1\n",
      "    조합 내 베스트 모델 갱신 (에폭 1), Val Loss: 0.1917. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_012_lr_0.0001_r_8_alpha_32_bs_64/best_model_in_combo\n",
      "  조합 12, 에폭 2: Train Loss=0.0442, Val Loss=0.1881, LR=1.00e-04\n",
      "    에폭 2 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_012_lr_0.0001_r_8_alpha_32_bs_64/epoch_2\n",
      "    조합 내 베스트 모델 갱신 (에폭 2), Val Loss: 0.1881. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_012_lr_0.0001_r_8_alpha_32_bs_64/best_model_in_combo\n",
      "  조합 12, 에폭 3: Train Loss=0.0313, Val Loss=0.1481, LR=1.00e-04\n",
      "    에폭 3 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_012_lr_0.0001_r_8_alpha_32_bs_64/epoch_3\n",
      "    조합 내 베스트 모델 갱신 (에폭 3), Val Loss: 0.1481. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_012_lr_0.0001_r_8_alpha_32_bs_64/best_model_in_combo\n",
      "  조합 12, 에폭 4: Train Loss=0.0303, Val Loss=0.1719, LR=1.00e-04\n",
      "    에폭 4 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_012_lr_0.0001_r_8_alpha_32_bs_64/epoch_4\n",
      "  조합 12, 에폭 5: Train Loss=0.0239, Val Loss=0.1994, LR=1.00e-04\n",
      "    에폭 5 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_012_lr_0.0001_r_8_alpha_32_bs_64/epoch_5\n",
      "  조합 12, 에폭 6: Train Loss=0.0244, Val Loss=0.1721, LR=1.00e-04\n",
      "    에폭 6 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_012_lr_0.0001_r_8_alpha_32_bs_64/epoch_6\n",
      "  조합 12, 에폭 7: Train Loss=0.0212, Val Loss=0.1871, LR=5.00e-05\n",
      "    에폭 7 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_012_lr_0.0001_r_8_alpha_32_bs_64/epoch_7\n",
      "  조합 12, 에폭 8: Train Loss=0.0212, Val Loss=0.2191, LR=5.00e-05\n",
      "    에폭 8 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_012_lr_0.0001_r_8_alpha_32_bs_64/epoch_8\n",
      "  조합 12, 에폭 9: Train Loss=0.0210, Val Loss=0.1759, LR=5.00e-05\n",
      "    에폭 9 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_012_lr_0.0001_r_8_alpha_32_bs_64/epoch_9\n",
      "  조합 12, 에폭 10: Train Loss=0.0217, Val Loss=0.1904, LR=2.50e-05\n",
      "    에폭 10 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_012_lr_0.0001_r_8_alpha_32_bs_64/epoch_10\n",
      "--- 그리드 서치 조합 12 완료. 이 조합의 최저 검증 손실: 0.1481 ---\n",
      "조합 12에 사용된 객체들의 메모리 해제를 시도합니다...\n",
      "GPU 캐시를 비웠습니다.\n",
      "가비지 컬렉터가 225개의 객체를 수거했습니다.\n",
      "\n",
      "--- 그리드 서치 조합 13/54 (combo_013_lr_0.0001_r_8_alpha_64_bs_32) 시작 ---\n",
      "현재 하이퍼파라미터: {'learning_rate': 0.0001, 'lora_r': 8, 'lora_alpha': 64, 'batch_size': 32, 'validation_split': 0.1}\n",
      "전체 데이터셋 크기: 25616\n",
      "학습 데이터셋 크기: 23055\n",
      "검증 데이터셋 크기: 2561\n",
      "학습 데이터로더 크기: 721\n",
      "검증 데이터로더 크기: 81\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db67245c292e4c5682125568ebbb52e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vocab size: 126464\n",
      "Resizing token embeddings to: 126977\n",
      "New vocab size: 126977\n",
      "QLoRA applied to LLaDA model.\n",
      "Making input embeddings trainable for newly added tokens...\n",
      "Input embeddings are now trainable.\n",
      "trainable params: 524,292,096 || all params: 8,021,876,736 || trainable%: 6.5358\n",
      "\n",
      "옵티마이저를 위한 파라미터 수집 중:\n",
      "옵티마이저를 위한 총 파라미터 그룹 수: 131\n",
      "\n",
      "옵티마이저 및 스케줄러 설정 완료.\n",
      "  조합 13, 에폭 1: Train Loss=0.5038, Val Loss=0.1888, LR=1.00e-04\n",
      "    에폭 1 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_013_lr_0.0001_r_8_alpha_64_bs_32/epoch_1\n",
      "    조합 내 베스트 모델 갱신 (에폭 1), Val Loss: 0.1888. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_013_lr_0.0001_r_8_alpha_64_bs_32/best_model_in_combo\n",
      "  조합 13, 에폭 2: Train Loss=0.0487, Val Loss=0.1389, LR=1.00e-04\n",
      "    에폭 2 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_013_lr_0.0001_r_8_alpha_64_bs_32/epoch_2\n",
      "    조합 내 베스트 모델 갱신 (에폭 2), Val Loss: 0.1389. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_013_lr_0.0001_r_8_alpha_64_bs_32/best_model_in_combo\n",
      "  조합 13, 에폭 3: Train Loss=0.0347, Val Loss=0.1266, LR=1.00e-04\n",
      "    에폭 3 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_013_lr_0.0001_r_8_alpha_64_bs_32/epoch_3\n",
      "    조합 내 베스트 모델 갱신 (에폭 3), Val Loss: 0.1266. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_013_lr_0.0001_r_8_alpha_64_bs_32/best_model_in_combo\n",
      "  조합 13, 에폭 4: Train Loss=0.0348, Val Loss=0.1162, LR=1.00e-04\n",
      "    에폭 4 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_013_lr_0.0001_r_8_alpha_64_bs_32/epoch_4\n",
      "    조합 내 베스트 모델 갱신 (에폭 4), Val Loss: 0.1162. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_013_lr_0.0001_r_8_alpha_64_bs_32/best_model_in_combo\n",
      "  조합 13, 에폭 5: Train Loss=0.0317, Val Loss=0.1326, LR=1.00e-04\n",
      "    에폭 5 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_013_lr_0.0001_r_8_alpha_64_bs_32/epoch_5\n",
      "  조합 13, 에폭 6: Train Loss=0.0247, Val Loss=0.1953, LR=1.00e-04\n",
      "    에폭 6 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_013_lr_0.0001_r_8_alpha_64_bs_32/epoch_6\n",
      "  조합 13, 에폭 7: Train Loss=0.0230, Val Loss=0.1619, LR=1.00e-04\n",
      "    에폭 7 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_013_lr_0.0001_r_8_alpha_64_bs_32/epoch_7\n",
      "  조합 13, 에폭 8: Train Loss=0.0193, Val Loss=0.1899, LR=5.00e-05\n",
      "    에폭 8 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_013_lr_0.0001_r_8_alpha_64_bs_32/epoch_8\n",
      "  조합 13, 에폭 9: Train Loss=0.0221, Val Loss=0.1595, LR=5.00e-05\n",
      "    에폭 9 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_013_lr_0.0001_r_8_alpha_64_bs_32/epoch_9\n",
      "  조합 13, 에폭 10: Train Loss=0.0231, Val Loss=0.1159, LR=5.00e-05\n",
      "    에폭 10 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_013_lr_0.0001_r_8_alpha_64_bs_32/epoch_10\n",
      "    조합 내 베스트 모델 갱신 (에폭 10), Val Loss: 0.1159. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_013_lr_0.0001_r_8_alpha_64_bs_32/best_model_in_combo\n",
      "--- 그리드 서치 조합 13 완료. 이 조합의 최저 검증 손실: 0.1159 ---\n",
      "조합 13에 사용된 객체들의 메모리 해제를 시도합니다...\n",
      "GPU 캐시를 비웠습니다.\n",
      "가비지 컬렉터가 99개의 객체를 수거했습니다.\n",
      "\n",
      "--- 그리드 서치 조합 14/54 (combo_014_lr_0.0001_r_8_alpha_64_bs_32) 시작 ---\n",
      "현재 하이퍼파라미터: {'learning_rate': 0.0001, 'lora_r': 8, 'lora_alpha': 64, 'batch_size': 32, 'validation_split': 0.2}\n",
      "전체 데이터셋 크기: 25616\n",
      "학습 데이터셋 크기: 20493\n",
      "검증 데이터셋 크기: 5123\n",
      "학습 데이터로더 크기: 641\n",
      "검증 데이터로더 크기: 161\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "540ef0dbbe024089ac9df21831cb591e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vocab size: 126464\n",
      "Resizing token embeddings to: 126977\n",
      "New vocab size: 126977\n",
      "QLoRA applied to LLaDA model.\n",
      "Making input embeddings trainable for newly added tokens...\n",
      "Input embeddings are now trainable.\n",
      "trainable params: 524,292,096 || all params: 8,021,876,736 || trainable%: 6.5358\n",
      "\n",
      "옵티마이저를 위한 파라미터 수집 중:\n",
      "옵티마이저를 위한 총 파라미터 그룹 수: 131\n",
      "\n",
      "옵티마이저 및 스케줄러 설정 완료.\n",
      "  조합 14, 에폭 1: Train Loss=0.5625, Val Loss=0.1824, LR=1.00e-04\n",
      "    에폭 1 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_014_lr_0.0001_r_8_alpha_64_bs_32/epoch_1\n",
      "    조합 내 베스트 모델 갱신 (에폭 1), Val Loss: 0.1824. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_014_lr_0.0001_r_8_alpha_64_bs_32/best_model_in_combo\n",
      "  조합 14, 에폭 2: Train Loss=0.0442, Val Loss=0.1375, LR=1.00e-04\n",
      "    에폭 2 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_014_lr_0.0001_r_8_alpha_64_bs_32/epoch_2\n",
      "    조합 내 베스트 모델 갱신 (에폭 2), Val Loss: 0.1375. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_014_lr_0.0001_r_8_alpha_64_bs_32/best_model_in_combo\n",
      "  조합 14, 에폭 3: Train Loss=0.0385, Val Loss=0.1471, LR=1.00e-04\n",
      "    에폭 3 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_014_lr_0.0001_r_8_alpha_64_bs_32/epoch_3\n",
      "  조합 14, 에폭 4: Train Loss=0.0325, Val Loss=0.1633, LR=1.00e-04\n",
      "    에폭 4 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_014_lr_0.0001_r_8_alpha_64_bs_32/epoch_4\n",
      "  조합 14, 에폭 5: Train Loss=0.0302, Val Loss=0.1541, LR=1.00e-04\n",
      "    에폭 5 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_014_lr_0.0001_r_8_alpha_64_bs_32/epoch_5\n",
      "  조합 14, 에폭 6: Train Loss=0.0234, Val Loss=0.1550, LR=5.00e-05\n",
      "    에폭 6 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_014_lr_0.0001_r_8_alpha_64_bs_32/epoch_6\n",
      "  조합 14, 에폭 7: Train Loss=0.0239, Val Loss=0.1551, LR=5.00e-05\n",
      "    에폭 7 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_014_lr_0.0001_r_8_alpha_64_bs_32/epoch_7\n",
      "  조합 14, 에폭 8: Train Loss=0.0208, Val Loss=0.1674, LR=5.00e-05\n",
      "    에폭 8 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_014_lr_0.0001_r_8_alpha_64_bs_32/epoch_8\n",
      "  조합 14, 에폭 9: Train Loss=0.0239, Val Loss=0.1519, LR=2.50e-05\n",
      "    에폭 9 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_014_lr_0.0001_r_8_alpha_64_bs_32/epoch_9\n",
      "  조합 14, 에폭 10: Train Loss=0.0266, Val Loss=0.1647, LR=2.50e-05\n",
      "    에폭 10 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_014_lr_0.0001_r_8_alpha_64_bs_32/epoch_10\n",
      "--- 그리드 서치 조합 14 완료. 이 조합의 최저 검증 손실: 0.1375 ---\n",
      "조합 14에 사용된 객체들의 메모리 해제를 시도합니다...\n",
      "GPU 캐시를 비웠습니다.\n",
      "가비지 컬렉터가 223개의 객체를 수거했습니다.\n",
      "\n",
      "--- 그리드 서치 조합 15/54 (combo_015_lr_0.0001_r_8_alpha_64_bs_32) 시작 ---\n",
      "현재 하이퍼파라미터: {'learning_rate': 0.0001, 'lora_r': 8, 'lora_alpha': 64, 'batch_size': 32, 'validation_split': 0.3}\n",
      "전체 데이터셋 크기: 25616\n",
      "학습 데이터셋 크기: 17932\n",
      "검증 데이터셋 크기: 7684\n",
      "학습 데이터로더 크기: 561\n",
      "검증 데이터로더 크기: 241\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25802067aee7490eafdf539412b22c6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vocab size: 126464\n",
      "Resizing token embeddings to: 126977\n",
      "New vocab size: 126977\n",
      "QLoRA applied to LLaDA model.\n",
      "Making input embeddings trainable for newly added tokens...\n",
      "Input embeddings are now trainable.\n",
      "trainable params: 524,292,096 || all params: 8,021,876,736 || trainable%: 6.5358\n",
      "\n",
      "옵티마이저를 위한 파라미터 수집 중:\n",
      "옵티마이저를 위한 총 파라미터 그룹 수: 131\n",
      "\n",
      "옵티마이저 및 스케줄러 설정 완료.\n",
      "  조합 15, 에폭 1: Train Loss=0.6303, Val Loss=0.1692, LR=1.00e-04\n",
      "    에폭 1 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_015_lr_0.0001_r_8_alpha_64_bs_32/epoch_1\n",
      "    조합 내 베스트 모델 갱신 (에폭 1), Val Loss: 0.1692. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_015_lr_0.0001_r_8_alpha_64_bs_32/best_model_in_combo\n",
      "  조합 15, 에폭 2: Train Loss=0.0524, Val Loss=0.1919, LR=1.00e-04\n",
      "    에폭 2 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_015_lr_0.0001_r_8_alpha_64_bs_32/epoch_2\n",
      "  조합 15, 에폭 3: Train Loss=0.0443, Val Loss=0.1744, LR=1.00e-04\n",
      "    에폭 3 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_015_lr_0.0001_r_8_alpha_64_bs_32/epoch_3\n",
      "  조합 15, 에폭 4: Train Loss=0.0370, Val Loss=0.1557, LR=1.00e-04\n",
      "    에폭 4 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_015_lr_0.0001_r_8_alpha_64_bs_32/epoch_4\n",
      "    조합 내 베스트 모델 갱신 (에폭 4), Val Loss: 0.1557. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_015_lr_0.0001_r_8_alpha_64_bs_32/best_model_in_combo\n",
      "  조합 15, 에폭 5: Train Loss=0.0339, Val Loss=0.1406, LR=1.00e-04\n",
      "    에폭 5 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_015_lr_0.0001_r_8_alpha_64_bs_32/epoch_5\n",
      "    조합 내 베스트 모델 갱신 (에폭 5), Val Loss: 0.1406. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_015_lr_0.0001_r_8_alpha_64_bs_32/best_model_in_combo\n",
      "  조합 15, 에폭 6: Train Loss=0.0320, Val Loss=0.1645, LR=1.00e-04\n",
      "    에폭 6 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_015_lr_0.0001_r_8_alpha_64_bs_32/epoch_6\n",
      "  조합 15, 에폭 7: Train Loss=0.0253, Val Loss=0.1509, LR=1.00e-04\n",
      "    에폭 7 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_015_lr_0.0001_r_8_alpha_64_bs_32/epoch_7\n",
      "  조합 15, 에폭 8: Train Loss=0.0278, Val Loss=0.1562, LR=1.00e-04\n",
      "    에폭 8 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_015_lr_0.0001_r_8_alpha_64_bs_32/epoch_8\n",
      "  조합 15, 에폭 9: Train Loss=0.0225, Val Loss=0.1682, LR=5.00e-05\n",
      "    에폭 9 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_015_lr_0.0001_r_8_alpha_64_bs_32/epoch_9\n",
      "  조합 15, 에폭 10: Train Loss=0.0208, Val Loss=0.1384, LR=5.00e-05\n",
      "    에폭 10 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_015_lr_0.0001_r_8_alpha_64_bs_32/epoch_10\n",
      "    조합 내 베스트 모델 갱신 (에폭 10), Val Loss: 0.1384. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_015_lr_0.0001_r_8_alpha_64_bs_32/best_model_in_combo\n",
      "--- 그리드 서치 조합 15 완료. 이 조합의 최저 검증 손실: 0.1384 ---\n",
      "조합 15에 사용된 객체들의 메모리 해제를 시도합니다...\n",
      "GPU 캐시를 비웠습니다.\n",
      "가비지 컬렉터가 99개의 객체를 수거했습니다.\n",
      "\n",
      "--- 그리드 서치 조합 16/54 (combo_016_lr_0.0001_r_8_alpha_64_bs_64) 시작 ---\n",
      "현재 하이퍼파라미터: {'learning_rate': 0.0001, 'lora_r': 8, 'lora_alpha': 64, 'batch_size': 64, 'validation_split': 0.1}\n",
      "전체 데이터셋 크기: 25616\n",
      "학습 데이터셋 크기: 23055\n",
      "검증 데이터셋 크기: 2561\n",
      "학습 데이터로더 크기: 361\n",
      "검증 데이터로더 크기: 41\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7cbb5b13814434284b189443dbbf861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vocab size: 126464\n",
      "Resizing token embeddings to: 126977\n",
      "New vocab size: 126977\n",
      "QLoRA applied to LLaDA model.\n",
      "Making input embeddings trainable for newly added tokens...\n",
      "Input embeddings are now trainable.\n",
      "trainable params: 524,292,096 || all params: 8,021,876,736 || trainable%: 6.5358\n",
      "\n",
      "옵티마이저를 위한 파라미터 수집 중:\n",
      "옵티마이저를 위한 총 파라미터 그룹 수: 131\n",
      "\n",
      "옵티마이저 및 스케줄러 설정 완료.\n",
      "  조합 16, 에폭 1: Train Loss=0.8693, Val Loss=0.1639, LR=1.00e-04\n",
      "    에폭 1 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_016_lr_0.0001_r_8_alpha_64_bs_64/epoch_1\n",
      "    조합 내 베스트 모델 갱신 (에폭 1), Val Loss: 0.1639. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_016_lr_0.0001_r_8_alpha_64_bs_64/best_model_in_combo\n",
      "  조합 16, 에폭 2: Train Loss=0.0388, Val Loss=0.1911, LR=1.00e-04\n",
      "    에폭 2 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_016_lr_0.0001_r_8_alpha_64_bs_64/epoch_2\n",
      "  조합 16, 에폭 3: Train Loss=0.0374, Val Loss=0.1313, LR=1.00e-04\n",
      "    에폭 3 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_016_lr_0.0001_r_8_alpha_64_bs_64/epoch_3\n",
      "    조합 내 베스트 모델 갱신 (에폭 3), Val Loss: 0.1313. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_016_lr_0.0001_r_8_alpha_64_bs_64/best_model_in_combo\n",
      "  조합 16, 에폭 4: Train Loss=0.0310, Val Loss=0.1434, LR=1.00e-04\n",
      "    에폭 4 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_016_lr_0.0001_r_8_alpha_64_bs_64/epoch_4\n",
      "  조합 16, 에폭 5: Train Loss=0.0251, Val Loss=0.1197, LR=1.00e-04\n",
      "    에폭 5 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_016_lr_0.0001_r_8_alpha_64_bs_64/epoch_5\n",
      "    조합 내 베스트 모델 갱신 (에폭 5), Val Loss: 0.1197. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_016_lr_0.0001_r_8_alpha_64_bs_64/best_model_in_combo\n",
      "  조합 16, 에폭 6: Train Loss=0.0265, Val Loss=0.1192, LR=1.00e-04\n",
      "    에폭 6 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_016_lr_0.0001_r_8_alpha_64_bs_64/epoch_6\n",
      "    조합 내 베스트 모델 갱신 (에폭 6), Val Loss: 0.1192. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_016_lr_0.0001_r_8_alpha_64_bs_64/best_model_in_combo\n",
      "  조합 16, 에폭 7: Train Loss=0.0272, Val Loss=0.1593, LR=1.00e-04\n",
      "    에폭 7 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_016_lr_0.0001_r_8_alpha_64_bs_64/epoch_7\n",
      "  조합 16, 에폭 8: Train Loss=0.0266, Val Loss=0.1463, LR=1.00e-04\n",
      "    에폭 8 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_016_lr_0.0001_r_8_alpha_64_bs_64/epoch_8\n",
      "  조합 16, 에폭 9: Train Loss=0.0244, Val Loss=0.1438, LR=1.00e-04\n",
      "    에폭 9 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_016_lr_0.0001_r_8_alpha_64_bs_64/epoch_9\n",
      "  조합 16, 에폭 10: Train Loss=0.0212, Val Loss=0.1488, LR=5.00e-05\n",
      "    에폭 10 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_016_lr_0.0001_r_8_alpha_64_bs_64/epoch_10\n",
      "--- 그리드 서치 조합 16 완료. 이 조합의 최저 검증 손실: 0.1192 ---\n",
      "조합 16에 사용된 객체들의 메모리 해제를 시도합니다...\n",
      "GPU 캐시를 비웠습니다.\n",
      "가비지 컬렉터가 225개의 객체를 수거했습니다.\n",
      "\n",
      "--- 그리드 서치 조합 17/54 (combo_017_lr_0.0001_r_8_alpha_64_bs_64) 시작 ---\n",
      "현재 하이퍼파라미터: {'learning_rate': 0.0001, 'lora_r': 8, 'lora_alpha': 64, 'batch_size': 64, 'validation_split': 0.2}\n",
      "전체 데이터셋 크기: 25616\n",
      "학습 데이터셋 크기: 20493\n",
      "검증 데이터셋 크기: 5123\n",
      "학습 데이터로더 크기: 321\n",
      "검증 데이터로더 크기: 81\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0650dfdce49442686accc3b3a06fd1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vocab size: 126464\n",
      "Resizing token embeddings to: 126977\n",
      "New vocab size: 126977\n",
      "QLoRA applied to LLaDA model.\n",
      "Making input embeddings trainable for newly added tokens...\n",
      "Input embeddings are now trainable.\n",
      "trainable params: 524,292,096 || all params: 8,021,876,736 || trainable%: 6.5358\n",
      "\n",
      "옵티마이저를 위한 파라미터 수집 중:\n",
      "옵티마이저를 위한 총 파라미터 그룹 수: 131\n",
      "\n",
      "옵티마이저 및 스케줄러 설정 완료.\n",
      "  조합 17, 에폭 1: Train Loss=0.9632, Val Loss=0.1970, LR=1.00e-04\n",
      "    에폭 1 모델 저장 완료: /workspace/min/pre_train/grid_search_results/combo_017_lr_0.0001_r_8_alpha_64_bs_64/epoch_1\n",
      "    조합 내 베스트 모델 갱신 (에폭 1), Val Loss: 0.1970. 저장 완료: /workspace/min/pre_train/grid_search_results/combo_017_lr_0.0001_r_8_alpha_64_bs_64/best_model_in_combo\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 147\u001b[0m\n\u001b[1;32m    145\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(params_to_optimize, max_grad_norm)\n\u001b[1;32m    149\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "LLADA_MODEL_NAME = \"GSAI-ML/LLaDA-8B-Base\" # 또는 사용 중인 모델명\n",
    "RVQ_N_EMB = 512  # RVQ 코드북의 임베딩 개수 (어휘 크기)\n",
    "RVQ_N_Q = 64     # RVQ 코드북 개수 (토큰 시퀀스 길이)\n",
    "BATCH_SIZE = 64   # GPU 메모리에 맞게 조정\n",
    "INIT_LR = 1e-4   # 초기 학습률\n",
    "NUM_EPOCHS = 10   # 학습 에폭 수\n",
    "VALIDATION_SPLIT = 0.1 \n",
    "max_grad_norm = 1.0\n",
    "model_save_path_base = \"/workspace/min/eeg_llada_mlm_model\"\n",
    "grid_search_results = []\n",
    "\n",
    "GRID_SEARCH_BASE_DIR = \"/workspace/min/pre_train/grid_search_results\" # 모든 그리드 서치 결과 저장 기본 폴더\n",
    "os.makedirs(GRID_SEARCH_BASE_DIR, exist_ok=True)\n",
    "OVERALL_BEST_MODEL_DIR = os.path.join(GRID_SEARCH_BASE_DIR, \"overall_best_model\")\n",
    "if os.path.exists(OVERALL_BEST_MODEL_DIR):\n",
    "    shutil.rmtree(OVERALL_BEST_MODEL_DIR)\n",
    "os.makedirs(OVERALL_BEST_MODEL_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"사용 디바이스: {DEVICE}\")\n",
    "\n",
    "rvq_tokenizer = RVQTokenizer(\n",
    "    feat=840, \n",
    "    latent=2048, # RVQ 내부 임베딩 차원, LLaDA hidden size와 다름\n",
    "    n_q=RVQ_N_Q, \n",
    "    n_emb=RVQ_N_EMB, \n",
    "    hidden=256,\n",
    "    TOKENIZER_CHECKPOINT_PATH=\"/workspace/min/tokenizer/tokenizer_epoch005.pt\" # 실제 경로로 수정!\n",
    ").to(DEVICE)\n",
    "rvq_tokenizer.eval() # 토크나이저는 학습하지 않으므로 eval 모드\n",
    "\n",
    "\n",
    "eeg_dataset_full = EEGDataset(data_dir=\"/workspace/dataset/combined_dataset.parquet\") # 실제 경로로 수정!\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [1e-4],\n",
    "    'lora_r': [8, 16, 32],\n",
    "    'lora_alpha': [16, 32, 64],\n",
    "    'batch_size': [32, 64], # GPU 메모리 상황에 따라 조절\n",
    "    'validation_split' : [0.1,0.2,0.3]\n",
    "    # 필요에 따라 다른 하이퍼파라미터 추가 가능 (예: lora_dropout, scheduler patience 등)\n",
    "}\n",
    "\n",
    "keys, values = zip(*param_grid.items())\n",
    "hyperparameter_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "print(f\"총 {len(hyperparameter_combinations)}개의 하이퍼파라미터 조합으로 그리드 서치를 수행합니다.\")\n",
    "\n",
    "\n",
    "all_epoch_logs_list = [] # 모든 에폭 로그를 저장할 리스트\n",
    "overall_best_val_loss = float('inf')\n",
    "\n",
    "for combo_idx, params in enumerate(hyperparameter_combinations):\n",
    "    combo_id_str = f\"combo_{combo_idx+1:03d}_lr_{params['learning_rate']}_r_{params['lora_r']}_alpha_{params['lora_alpha']}_bs_{params['batch_size']}\"\n",
    "    print(f\"\\n--- 그리드 서치 조합 {combo_idx+1}/{len(hyperparameter_combinations)} ({combo_id_str}) 시작 ---\")\n",
    "    print(f\"현재 하이퍼파라미터: {params}\")\n",
    "\n",
    "    current_combo_save_dir = os.path.join(GRID_SEARCH_BASE_DIR, combo_id_str)\n",
    "    os.makedirs(current_combo_save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "    current_lr = params['learning_rate']\n",
    "    current_lora_r = params['lora_r']\n",
    "    current_lora_alpha = params['lora_alpha']\n",
    "    current_batch_size = params['batch_size']\n",
    "    current_validation_slplit = params['validation_split']\n",
    "\n",
    "    set_seeds(SEED) \n",
    "\n",
    "    # 데이터셋 분할\n",
    "    dataset_size = len(eeg_dataset_full)\n",
    "    val_size = int(dataset_size * current_validation_slplit)\n",
    "    train_size = dataset_size - val_size\n",
    "    \n",
    "    print(f\"전체 데이터셋 크기: {dataset_size}\")\n",
    "    print(f\"학습 데이터셋 크기: {train_size}\")\n",
    "    print(f\"검증 데이터셋 크기: {val_size}\")\n",
    "    \n",
    "    # random_split을 사용하여 데이터셋 분할 (시드 고정으로 재현성 확보 가능)\n",
    "    # torch.manual_seed(42) # 필요시 시드 고정\n",
    "    train_dataset, val_dataset = random_split(eeg_dataset_full, [train_size, val_size])\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=current_batch_size, shuffle=True, collate_fn=collate_fn_eeg_mlm, worker_init_fn=seed_worker if 'seed_worker' in globals() else None)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=current_batch_size, shuffle=False, collate_fn=collate_fn_eeg_mlm, worker_init_fn=seed_worker if 'seed_worker' in globals() else None)\n",
    "    \n",
    "    print(f\"학습 데이터로더 크기: {len(train_dataloader)}\")\n",
    "    print(f\"검증 데이터로더 크기: {len(val_dataloader)}\")\n",
    "    \n",
    "    \n",
    "    # EEG_LLaDA_MLM 모델 초기화 (이전 코드에서 정의된 클래스 사용)\n",
    "    qlora_params_config = {\n",
    "        \"r\": current_lora_r,\n",
    "        \"lora_alpha\": current_lora_alpha,\n",
    "        \"lora_dropout\": 0.05,\n",
    "        \"target_modules\": [\"q_proj\", \"v_proj\"] # LLaDA 모델 구조에 맞게 명시적 지정 권장 (이전 안내 참조)\n",
    "    }\n",
    "    model = EEG_LLaDA_MLM(\n",
    "        llada_model_name=LLADA_MODEL_NAME, \n",
    "        rvq_n_emb=RVQ_N_EMB, \n",
    "        use_qlora=True,\n",
    "        qlora_config_params=qlora_params_config\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    params_to_optimize = []\n",
    "    print(\"\\n옵티마이저를 위한 파라미터 수집 중:\")\n",
    "    for name, param in model.llada_model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            params_to_optimize.append(param)\n",
    "            #print(f\"  LLaDA (PEFT): {name} (모양: {param.shape}, dtype: {param.dtype})\")\n",
    "    \n",
    "    for name, param in model.mlm_head.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            params_to_optimize.append(param)\n",
    "            #print(f\"  MLM 헤드: {name} (모양: {param.shape}, dtype: {param.dtype})\")\n",
    "    \n",
    "    if not params_to_optimize:\n",
    "        raise ValueError(\"학습할 파라미터가 없습니다. 모델 설정을 확인하세요.\")\n",
    "    print(f\"옵티마이저를 위한 총 파라미터 그룹 수: {len(params_to_optimize)}\")\n",
    "    \n",
    "    optimizer = optim.AdamW(params_to_optimize, lr=current_lr)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=False) # verbose 줄임\n",
    "    \n",
    "    print(\"\\n옵티마이저 및 스케줄러 설정 완료.\")\n",
    "\n",
    "    best_val_loss_this_combo = float('inf')\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        total_train_loss_epoch = 0\n",
    "        for step, batch_eeg_tensors in enumerate(train_dataloader):\n",
    "            batch_eeg_tensors = batch_eeg_tensors.to(DEVICE)\n",
    "            with torch.no_grad():\n",
    "                _, local_eeg_indices_batch = rvq_tokenizer(batch_eeg_tensors)\n",
    "                original_local_eeg_ids = local_eeg_indices_batch.squeeze(1)\n",
    "            global_original_eeg_ids = original_local_eeg_ids + model.v_text\n",
    "            masked_global_eeg_ids_for_input, masked_indices = forward_process_eeg(\n",
    "                global_original_eeg_ids, model.global_mask_eeg_token_id)\n",
    "            mlm_labels = original_local_eeg_ids.clone()\n",
    "            mlm_labels[~masked_indices] = -100\n",
    "            attention_mask = torch.ones_like(original_local_eeg_ids, device=DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(masked_global_eeg_ids_for_input=masked_global_eeg_ids_for_input,\n",
    "                            attention_mask=attention_mask, mlm_labels=mlm_labels)\n",
    "            loss = outputs[\"loss\"]\n",
    "            if loss is None: continue\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(params_to_optimize, max_grad_norm)\n",
    "            optimizer.step()\n",
    "            total_train_loss_epoch += loss.item()\n",
    "        \n",
    "        avg_train_loss_epoch = total_train_loss_epoch / len(train_dataloader)\n",
    "        avg_val_loss_epoch = evaluate_model(model, val_dataloader, DEVICE, rvq_tokenizer) # evaluate_model 함수는 이전에 정의됨\n",
    "        \n",
    "        print(f\"  조합 {combo_idx+1}, 에폭 {epoch+1}: Train Loss={avg_train_loss_epoch:.4f}, Val Loss={avg_val_loss_epoch:.4f}, LR={optimizer.param_groups[0]['lr']:.2e}\")\n",
    "        scheduler.step(avg_val_loss_epoch)\n",
    "\n",
    "        # CSV 로깅을 위한 데이터 추가\n",
    "        epoch_log_entry = params.copy() # 현재 하이퍼파라미터 복사\n",
    "        epoch_log_entry['combo_id_str'] = combo_id_str\n",
    "        epoch_log_entry['combo_idx'] = combo_idx + 1\n",
    "        epoch_log_entry['epoch'] = epoch + 1\n",
    "        epoch_log_entry['train_loss'] = avg_train_loss_epoch\n",
    "        epoch_log_entry['validation_loss'] = avg_val_loss_epoch\n",
    "        epoch_log_entry['current_lr_epoch_end'] = optimizer.param_groups[0]['lr']\n",
    "        all_epoch_logs_list.append(epoch_log_entry)\n",
    "\n",
    "        # 매 에폭 모델 저장\n",
    "        epoch_model_save_dir = os.path.join(current_combo_save_dir, f\"epoch_{epoch+1}\")\n",
    "        os.makedirs(epoch_model_save_dir, exist_ok=True)\n",
    "        model.llada_model.save_pretrained(os.path.join(epoch_model_save_dir, \"qlora_adapter\"))\n",
    "        torch.save(model.mlm_head.state_dict(), os.path.join(epoch_model_save_dir, \"mlm_head.pth\"))\n",
    "        print(f\"    에폭 {epoch+1} 모델 저장 완료: {epoch_model_save_dir}\")\n",
    "\n",
    "        # 현재 조합 내에서 베스트 모델 업데이트 및 저장\n",
    "        if avg_val_loss_epoch < best_val_loss_this_combo:\n",
    "            best_val_loss_this_combo = avg_val_loss_epoch\n",
    "            combo_best_model_save_dir = os.path.join(current_combo_save_dir, \"best_model_in_combo\")\n",
    "            os.makedirs(combo_best_model_save_dir, exist_ok=True)\n",
    "            model.llada_model.save_pretrained(os.path.join(combo_best_model_save_dir, \"qlora_adapter\"))\n",
    "            torch.save(model.mlm_head.state_dict(), os.path.join(combo_best_model_save_dir, \"mlm_head.pth\"))\n",
    "            print(f\"    조합 내 베스트 모델 갱신 (에폭 {epoch+1}), Val Loss: {best_val_loss_this_combo:.4f}. 저장 완료: {combo_best_model_save_dir}\")\n",
    "\n",
    "        # 전체 그리드 서치 중 베스트 모델 업데이트 및 저장\n",
    "        if avg_val_loss_epoch < overall_best_val_loss:\n",
    "            overall_best_val_loss = avg_val_loss_epoch\n",
    "            print(f\"    ✨ 전체 베스트 모델 갱신 (조합 {combo_idx+1}, 에폭 {epoch+1}), Val Loss: {overall_best_val_loss:.4f}. 저장 중...\")\n",
    "            # if os.path.exists(OVERALL_BEST_MODEL_DIR): # 이전 베스트 모델 폴더 삭제\n",
    "            #     shutil.rmtree(OVERALL_BEST_MODEL_DIR)\n",
    "            # os.makedirs(OVERALL_BEST_MODEL_DIR, exist_ok=True) # 삭제 후 다시 생성\n",
    "            model.llada_model.save_pretrained(os.path.join(OVERALL_BEST_MODEL_DIR, \"qlora_adapter\"))\n",
    "            torch.save(model.mlm_head.state_dict(), os.path.join(OVERALL_BEST_MODEL_DIR, \"mlm_head.pth\"))\n",
    "            # 베스트 모델 정보 저장 (어떤 조합과 에폭이었는지)\n",
    "            with open(os.path.join(OVERALL_BEST_MODEL_DIR, \"best_model_info.txt\"), \"w\") as f:\n",
    "                f.write(f\"Best model from combination: {combo_id_str}\\n\")\n",
    "                f.write(f\"Epoch: {epoch+1}\\n\")\n",
    "                f.write(f\"Validation Loss: {overall_best_val_loss:.4f}\\n\")\n",
    "                f.write(f\"Hyperparameters: {params}\\n\")\n",
    "            print(f\"    ✨ 전체 베스트 모델 저장 완료: {OVERALL_BEST_MODEL_DIR}\")\n",
    "            \n",
    "    print(f\"--- 그리드 서치 조합 {combo_idx+1} 완료. 이 조합의 최저 검증 손실: {best_val_loss_this_combo:.4f} ---\")\n",
    "\n",
    "    # --- 메모리 해제 시작 ---\n",
    "    print(f\"조합 {combo_idx+1}에 사용된 객체들의 메모리 해제를 시도합니다...\")\n",
    "    # 1. 모델, 옵티마이저, 스케줄러 삭제\n",
    "    del model\n",
    "    del optimizer\n",
    "    del scheduler\n",
    "    # 필요하다면 데이터로더도 삭제 (만약 루프 내에서 매번 재생성된다면)\n",
    "    # del train_dataloader\n",
    "    # del val_dataloader \n",
    "    # (주의: train_dataset, val_dataset은 random_split으로 생성되므로, \n",
    "    #  eeg_dataset_full이 루프 밖에 있다면 이들은 삭제하지 않아도 됩니다.\n",
    "    #  만약 eeg_dataset_full도 루프 안에서 매번 로드한다면 삭제 대상입니다.)\n",
    "\n",
    "    # 2. GPU 캐시 비우기 (PyTorch)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"GPU 캐시를 비웠습니다.\")\n",
    "\n",
    "    # 3. 파이썬 가비지 컬렉터 명시적 호출\n",
    "    collected_count = gc.collect()\n",
    "    print(f\"가비지 컬렉터가 {collected_count}개의 객체를 수거했습니다.\")\n",
    "    # --- 메모리 해제 완료 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "모든 에폭 로그가 CSV 파일로 저장되었습니다: /workspace/min/pre_train/grid_search_results/grid_search_epoch_logs.csv\n",
      "\n",
      "--- 그리드 서치 최종 완료 ---\n",
      "전체 실험 중 가장 낮은 검증 손실: 0.1157\n",
      "가장 좋은 성능을 보인 모델은 /workspace/min/pre_train/grid_search_results/overall_best_model 에 저장되었습니다.\n",
      "최고 성능 모델 정보:\n",
      "Best model from combination: combo_007_lr_0.0001_r_8_alpha_32_bs_32\n",
      "Epoch: 4\n",
      "Validation Loss: 0.1157\n",
      "Hyperparameters: {'learning_rate': 0.0001, 'lora_r': 8, 'lora_alpha': 32, 'batch_size': 32, 'validation_split': 0.1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 그리드 서치 종료 후 CSV 로그 저장 ---\n",
    "if all_epoch_logs_list:\n",
    "    log_df = pd.DataFrame(all_epoch_logs_list)\n",
    "    csv_save_path = os.path.join(GRID_SEARCH_BASE_DIR, \"grid_search_epoch_logs.csv\")\n",
    "    log_df.to_csv(csv_save_path, index=False)\n",
    "    print(f\"\\n모든 에폭 로그가 CSV 파일로 저장되었습니다: {csv_save_path}\")\n",
    "else:\n",
    "    print(\"\\n기록된 에폭 로그가 없습니다.\")\n",
    "\n",
    "print(f\"\\n--- 그리드 서치 최종 완료 ---\")\n",
    "print(f\"전체 실험 중 가장 낮은 검증 손실: {overall_best_val_loss:.4f}\")\n",
    "print(f\"가장 좋은 성능을 보인 모델은 {OVERALL_BEST_MODEL_DIR} 에 저장되었습니다.\")\n",
    "if os.path.exists(os.path.join(OVERALL_BEST_MODEL_DIR, \"best_model_info.txt\")):\n",
    "    with open(os.path.join(OVERALL_BEST_MODEL_DIR, \"best_model_info.txt\"), \"r\") as f:\n",
    "        print(\"최고 성능 모델 정보:\")\n",
    "        print(f.read())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM83/cOrPVaxgOV9Dykm0vP",
   "gpuType": "A100",
   "machine_shape": "hm",
   "mount_file_id": "14ytFeJZTrs1Iuxs4txv7AxxTEj_sT2hO",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "PyTorch 2.5 (NGC 24.09/Python 3.10) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1ef27ea2e0264c0e94520ea1e9ec47a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "50f40a527f7e4d6c9af92a4e80136498": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e5e7118945440c0918a6ab2176f3512",
      "placeholder": "​",
      "style": "IPY_MODEL_e3473cea30f545069983b0c09005840a",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "64f3dc6feb69453ab5635b471a280b0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ef27ea2e0264c0e94520ea1e9ec47a9",
      "max": 6,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_837b58da5af44e429cc334262d22cba5",
      "value": 6
     }
    },
    "6f28c65545ff48b7ba75e9baa7945ef5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_50f40a527f7e4d6c9af92a4e80136498",
       "IPY_MODEL_64f3dc6feb69453ab5635b471a280b0c",
       "IPY_MODEL_f7adee33a524499ead533248d3f4580c"
      ],
      "layout": "IPY_MODEL_eba5ef1393884ffc99e76b42dfa7c4bb"
     }
    },
    "837b58da5af44e429cc334262d22cba5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9e5e7118945440c0918a6ab2176f3512": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be5f991fb5844888b2b57cd35e8bbc00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e3473cea30f545069983b0c09005840a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eba5ef1393884ffc99e76b42dfa7c4bb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f7adee33a524499ead533248d3f4580c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc6bd1bd0ed14514afa3091399661903",
      "placeholder": "​",
      "style": "IPY_MODEL_be5f991fb5844888b2b57cd35e8bbc00",
      "value": " 6/6 [00:18&lt;00:00,  3.17s/it]"
     }
    },
    "fc6bd1bd0ed14514afa3091399661903": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
