{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "291fb3d4-b4a6-4bfe-bfd3-caeede3477b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b7e91745-27fa-4e2f-a3d2-664d718780a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 128        # 128\n",
    "N_Q        = 12         # 12\n",
    "N_EMB      = 64         # 64\n",
    "CODEBOOK_SIZE = 512     # 512 -> 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "346d5a38-903a-4fb7-8868-f268efed3e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RVQ(nn.Module):\n",
    "    \"\"\"Residual Vector Quantization with multiple codebooks.\"\"\"\n",
    "    def __init__(self, num_quantizers=N_Q, num_embeddings=N_EMB, embedding_dim=LATENT_DIM):\n",
    "        super().__init__()\n",
    "        self.num_quantizers = num_quantizers\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.codebooks = nn.ModuleList(\n",
    "            [nn.Embedding(num_embeddings, embedding_dim) for _ in range(num_quantizers)]\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        # z: (B, L, D)\n",
    "        residual = z\n",
    "        quantized = torch.zeros_like(z)\n",
    "        all_indices = []\n",
    "        for codebook in self.codebooks:\n",
    "            weight = codebook.weight  # (K, D)\n",
    "            # compute L2 distance\n",
    "            dist = ((residual.unsqueeze(2) - weight.unsqueeze(0).unsqueeze(0))**2).sum(-1)\n",
    "            indices = dist.argmin(-1)        # (B, L)\n",
    "            all_indices.append(indices)\n",
    "            q = F.embedding(indices, weight) # (B, L, D)\n",
    "            quantized += q\n",
    "            # ── γ 스케줄링: 앞단(0) 0.88 → 뒷단(7) 0.95 ──────────────────\n",
    "            gamma_start, gamma_end = 0.80, 0.95\n",
    "            level = len(all_indices)                      # 현재 레벨 l\n",
    "            gamma = gamma_start + (gamma_end - gamma_start) * (level / (self.num_quantizers - 1))\n",
    "            residual = gamma * (residual - q)\n",
    "            # residual = 0.88 * (residual - q)\n",
    "            # residual = residual - q\n",
    "        return quantized, all_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9123c8be-6c43-411f-9137-af2015161c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvEEGEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    840-dim 벡터를 1×840 시퀀스로 보고 Conv1D 두 층으로 잠재표현 생성\n",
    "    출력은 (B, latent_dim)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=840, latent_dim=LATENT_DIM, hidden=256):\n",
    "        super().__init__()\n",
    "        self.conv_stack = nn.Sequential(\n",
    "            nn.Conv1d(1, hidden, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.Conv1d(hidden, latent_dim, kernel_size=3, padding=1), nn.ReLU()\n",
    "        )\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)   # 길이 840 → 1 로 압축\n",
    "\n",
    "    def forward(self, x):           # x: (B, feat)\n",
    "        x = x.unsqueeze(1)          # (B, 1, 840)\n",
    "        z = self.conv_stack(x)      # (B, latent_dim, 840)\n",
    "        z = self.pool(z).squeeze(-1)  # (B, latent_dim)\n",
    "        return z\n",
    "\n",
    "class ConvEEGDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    latent (B,D) → (B,840)\n",
    "    105→210→420→840 업샘플링\n",
    "    \"\"\"\n",
    "    def __init__(self, output_dim=840, latent_dim=LATENT_DIM, hidden=256):\n",
    "        super().__init__()\n",
    "        self.start_len = 105                         # 105×8=840\n",
    "        self.fc = nn.Linear(latent_dim, latent_dim * self.start_len)\n",
    "\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose1d(latent_dim, hidden, kernel_size=4, stride=2, padding=1),  # 105→210\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(hidden, hidden, kernel_size=4, stride=2, padding=1),      # 210→420\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(hidden, 1, kernel_size=4, stride=2, padding=1)            # 420→840\n",
    "        )\n",
    "\n",
    "    def forward(self, zq):                # (B, latent)\n",
    "        h = self.fc(zq).view(zq.size(0), -1, self.start_len)  # (B, latent, 105)\n",
    "        x_hat = self.deconv(h)            # (B, 1, 840)\n",
    "        return x_hat.squeeze(1)           # (B, 840)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a512d2a9-149c-408d-9e52-4048d3167b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvRVQAutoEncoder(nn.Module):\n",
    "    def __init__(self, feat=840, latent=LATENT_DIM, n_q=N_Q, n_emb=CODEBOOK_SIZE, hidden=256):\n",
    "        super().__init__()\n",
    "        self.enc = ConvEEGEncoder(feat, latent, hidden)\n",
    "        self.rvq = RVQ(num_quantizers=n_q, num_embeddings=n_emb, embedding_dim=latent)\n",
    "        self.dec = ConvEEGDecoder(feat, latent, hidden)\n",
    "\n",
    "    def forward(self, x):           # x: (B, 840)\n",
    "        z = self.enc(x)             # (B, latent)\n",
    "        zq, indices = self.rvq(z.unsqueeze(1))  # (B, 1, D)\n",
    "        zq = zq.squeeze(1)          # (B, D) — 디코더용으로 다시 압축\n",
    "        x_hat = self.dec(zq)        # (B, 840)\n",
    "        return x_hat, z, zq, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "db3e1c72-eb1f-46b6-bb55-cd18681a7520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rvq_loss(x, x_hat, z, z_q, beta=0.05):\n",
    "    # 재구성 손실 (L_R)\n",
    "    reconstruction_loss = F.mse_loss(x_hat, x)\n",
    "\n",
    "    # 코드북 손실 (첫 번째 항 of L_VQ)\n",
    "    # z는 인코더 출력 z_e(x), z_q는 양자화된 벡터 e\n",
    "    # sg[z_e(x)] - e  <-->  z.detach() - z_q\n",
    "    codebook_loss = F.mse_loss(z.detach(), z_q)\n",
    "\n",
    "    # 커밋먼트 손실 (두 번째 항 of L_VQ)\n",
    "    # z_e(x) - sg[e]  <-->  z - z_q.detach()\n",
    "    commitment_loss = F.mse_loss(z, z_q.detach())\n",
    "\n",
    "    # 전체 손실: L_R + L_VQ (여기서 L_VQ = codebook_loss + beta * commitment_loss)\n",
    "    # 논문에서는 L_VQ의 두 항에 대한 상대적 가중치를 명시하지 않았으므로,\n",
    "    # 코드북 손실의 가중치는 1로 가정합니다.\n",
    "    return reconstruction_loss, codebook_loss, beta * commitment_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "104cba66-4c22-4ba9-9f69-54130d27adab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class EEGVecDataset(Dataset):\n",
    "    \"\"\"\n",
    "    EEG word-level feature 벡터 하나를 그대로 토큰으로 사용.\n",
    "    \"\"\"\n",
    "    def __init__(self, np_array):              # np_array: (N, feat)\n",
    "        mu, std = np_array.mean(0, keepdims=True), np_array.std(0, keepdims=True)+1e-8\n",
    "        self.data = (np_array - mu) / std      # 정규화\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.data[idx])    # shape: (feat,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "84ddf43b-6393-415e-b2ec-6e5a63f03df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch.utils.data import Sampler\n",
    "\n",
    "class UniqueFirstSampler(Sampler):\n",
    "    \"\"\"\n",
    "    에폭마다:\n",
    "      ① unique 인덱스를 랜덤 순서로 모두 배치\n",
    "      ② 남은 duplicate 인덱스를 랜덤 순서로 뒤에 붙임\n",
    "    \"\"\"\n",
    "    def __init__(self, uniq_idx, dup_idx, shuffle=True):\n",
    "        self.uniq_idx = uniq_idx\n",
    "        self.dup_idx  = dup_idx\n",
    "        self.shuffle  = shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.uniq_idx)\n",
    "            random.shuffle(self.dup_idx)\n",
    "        # unique 우선 + duplicate\n",
    "        full_order = self.uniq_idx + self.dup_idx\n",
    "        return iter(full_order)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.uniq_idx) + len(self.dup_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d6381206-ae69-48f0-aa47-a67ee4876c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306211, 840) float32\n",
      "unique 8855, duplicate 297356\n"
     ]
    }
   ],
   "source": [
    "# (1) 벡터 수집 --------------------------------------------------------\n",
    "data_dir   = \"/home/work/skku/hyo/hyo/dataset/word.parquet\"\n",
    "df = pd.read_parquet(data_dir)\n",
    "eeg_vecs = df[\"eeg\"].to_numpy()\n",
    "\n",
    "arr = np.stack(eeg_vecs).astype(np.float32)\n",
    "arr = np.nan_to_num(arr, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "print(arr.shape, arr.dtype)  # → (N, 840) float32\n",
    "\n",
    "unique_mask = ~df[\"text\"].duplicated(keep=\"first\")\n",
    "unique_indices     = np.where(unique_mask)[0].tolist()\n",
    "duplicate_indices  = np.where(~unique_mask)[0].tolist()\n",
    "\n",
    "print(f\"unique {len(unique_indices)}, duplicate {len(duplicate_indices)}\")\n",
    "\n",
    "# 5) Dataset & DataLoader\n",
    "dataset = EEGVecDataset(arr)             # now each item is (840,) vector\n",
    "# loader  = DataLoader(dataset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "281bccef-9a5f-4e1f-861a-07a7fd55434a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FreqAwareSampler(Sampler):\n",
    "    \"\"\"\n",
    "    상위 top_k 빈도 단어는 keep_ratio 만큼만 사용,\n",
    "    나머지는 전부 유지해 빈도를 평탄화한다.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, top_k=200, keep_ratio=0.2, shuffle=True):\n",
    "        self.shuffle = shuffle\n",
    "        top_words = df['text'].value_counts().head(top_k).index\n",
    "        hi = df['text'].isin(top_words)\n",
    "        hi_idx = df[hi].sample(frac=keep_ratio, random_state=42).index.tolist()\n",
    "        lo_idx = df[~hi].index.tolist()\n",
    "        self.indices = hi_idx + lo_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.indices)\n",
    "        return iter(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "96b96152-8cb8-4b79-86a7-0c4a4a3f7fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2924a4ae-2535-462b-ac31-e0a7e497078c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "def kmeans_init(model, dataloader, k=CODEBOOK_SIZE, max_samples=30000):\n",
    "    \"\"\"\n",
    "    encoder latent 샘플 → K-means → centroids(Tensor, k×latent_dim)\n",
    "    - k가 데이터 수보다 크면 k = 데이터 수 // 2 로 자동 축소\n",
    "    \"\"\"\n",
    "    buf = []\n",
    "    with torch.no_grad():\n",
    "        for x in dataloader:\n",
    "            buf.append(model.enc(x.to(device)))\n",
    "            if len(torch.cat(buf)) >= max_samples:\n",
    "                break\n",
    "    latent = torch.cat(buf).cpu().numpy()         # (S, latent_dim)\n",
    "    n_train = latent.shape[0]\n",
    "\n",
    "    if n_train < k * 40:                          # faiss 권장치 미달 시 k 축소\n",
    "        k_new = max(8, n_train // 40)\n",
    "        print(f\"⚠️  samples({n_train}) ≪ {k}×40,  k→{k_new}\")\n",
    "        k = k_new\n",
    "\n",
    "    import faiss\n",
    "    km = faiss.Kmeans(d=latent.shape[1], k=k, niter=20, verbose=False)\n",
    "    km.train(latent)\n",
    "\n",
    "    # 대부분의 faiss 버전은 km.centroids 속성 사용\n",
    "    return torch.tensor(km.centroids).float()     # (k, latent_dim)\n",
    "\n",
    "def usage_loss(idx_list, num_emb, lam_vec):\n",
    "    losses = []\n",
    "    for idx, lam in zip(idx_list, lam_vec):\n",
    "        flat = idx.view(-1)\n",
    "        hist = torch.bincount(flat, minlength=num_emb).float()\n",
    "        p = hist / hist.sum()\n",
    "        entropy = -(p[p>0] * torch.log(p[p>0])).sum()\n",
    "        losses.append(-lam * entropy)\n",
    "    return sum(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "073dfd1e-0dab-4b5b-8e3a-226f42813288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ all codebooks initialised (K-means per level)\n"
     ]
    }
   ],
   "source": [
    "model = ConvRVQAutoEncoder().to(device)\n",
    "\n",
    "tmp_loader = DataLoader(dataset, batch_size=256, shuffle=True, num_workers=0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # latent 샘플 추출\n",
    "    buf = []\n",
    "    for x in DataLoader(dataset, batch_size=512, shuffle=True):\n",
    "        buf.append(model.enc(x.to(device)))\n",
    "        if len(torch.cat(buf)) >= 50000: break\n",
    "    z_full = torch.cat(buf)                     # (S,128)\n",
    "\n",
    "    residual = z_full.clone().to(device)        # 첫 레벨 입력 (CPU 이동은 아래에서)\n",
    "    for l, cb in enumerate(model.rvq.codebooks):\n",
    "        lat_np = residual.cpu().numpy()\n",
    "        km     = faiss.Kmeans(d=LATENT_DIM, k=CODEBOOK_SIZE, niter=15, verbose=False)\n",
    "        km.train(lat_np)\n",
    "        cb.weight.data.copy_(torch.tensor(km.centroids).to(device))\n",
    "\n",
    "        # 다음 레벨 residual 계산\n",
    "        weight = cb.weight                       # (K,128)\n",
    "        dist   = ((residual.unsqueeze(1) - weight)**2).sum(-1)   # (S,K)\n",
    "        idx    = dist.argmin(1)                  # (S,)\n",
    "        q      = weight[idx]                     # (S,128)\n",
    "        residual = residual - q                  # 잔차 업데이트\n",
    "print(\"✔ all codebooks initialised (K-means per level)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "333f3df9-bae8-4027-85bf-bfbd112a5764",
   "metadata": {},
   "outputs": [],
   "source": [
    "STAGE_EPOCH = 10        # 0-1ep: level0, 2-3ep: level0-1, …\n",
    "LAMBDA_USAGE = 0.05\n",
    "RECON_THR  = 0.99      # 재구성 MSE가 0.50 보다 작을 때만\n",
    "USAGE_THR  = -0.30     # usage_loss 가 -0.05 보다 작을 때만 (엔트로피↑)\n",
    "SIGMA = 0.05              # dead-code 재초기화 범위\n",
    "DEAD_THRESH = 0.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "79aff7b7-38c7-4a36-a6f1-0c1aa220d17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import csv\n",
    "import os\n",
    "\n",
    "init_lr   = 1.0e-4\n",
    "optimizer = optim.AdamW(model.parameters(), lr=init_lr)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.7,\n",
    "    patience=1,\n",
    "    min_lr=5e-5\n",
    ")\n",
    "\n",
    "#── 로그 파일 준비 ──\n",
    "log_path = \"/home/work/skku/hyo/hyo/model/rvq_best_model_word_5.log\"\n",
    "\n",
    "#── 학습 루프 ──\n",
    "best_loss = float('inf')\n",
    "best_model_path = \"/home/work/skku/hyo/hyo/model/rvq_best_model_word_5.pt\"\n",
    "\n",
    "for epoch in range(30):\n",
    "    cum_loss   = 0.0\n",
    "    cum_recon  = 0.0\n",
    "    cum_code   = 0.0\n",
    "    cum_commit = 0.0\n",
    "    cum_usage  = 0.0\n",
    "    steps = 0\n",
    "\n",
    "    # ── 3-A. 현재 활성 스테이지 계산 & freeze ──\n",
    "    cur_stage = min(epoch // STAGE_EPOCH, N_Q - 1)\n",
    "    for l, cb in enumerate(model.rvq.codebooks):\n",
    "        cb.weight.requires_grad_(l <= cur_stage)\n",
    "\n",
    "    # encoder warm-up(앞 2 epoch freeze)\n",
    "    enc_grad = epoch >= 2\n",
    "    for p in model.enc.parameters():\n",
    "        p.requires_grad = enc_grad\n",
    "\n",
    "    sampler = FreqAwareSampler(df, top_k=200, keep_ratio=0.2)\n",
    "    loader = DataLoader(dataset, batch_size=256, sampler=sampler, num_workers=0)\n",
    "\n",
    "    active_sets = [set() for _ in range(N_Q)]\n",
    "\n",
    "    for x in loader:\n",
    "        steps += 1\n",
    "        x = x.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        x_hat, z, z_q, idx_list = model(x)\n",
    "\n",
    "        # ── active code 집계 ───────────────────────────────\n",
    "        for l, idx in enumerate(idx_list):\n",
    "            active_sets[l].update(idx.view(-1).tolist())\n",
    "\n",
    "        recon_loss, codebook_loss, commit_loss = rvq_loss(x, x_hat, z, z_q)\n",
    "\n",
    "        # lam_vec = [0.03,0.04,0.06,0.08,0.12,0.15,0.18,0.20]\n",
    "        # lam_vec = [0.20,0.18,0.15,0.12,0.10,0.08,0.06,0.04]\n",
    "        # lam_vec = [1.0,0.8,0.6,0.3,0.12,0.08,0.05,0.03]\n",
    "        lam_vec = [1.00,0.80,0.60,0.40,0.18,0.12,0.08,0.06,0.05,0.04,0.03,0.02]\n",
    "        # lam_vec = [0.25,0.20,0.15,0.12,0.10,0.08,0.06,0.05,0.04,0.03,0.02,0.01]\n",
    "        # lam_vec = [0.05,0.06,0.07,0.08,0.08,0.08,0.07,0.06,0.05,0.04,0.03,0.02]\n",
    "        u_loss = usage_loss(idx_list, CODEBOOK_SIZE, lam_vec)\n",
    "        # u_loss = usage_loss(idx_list, CODEBOOK_SIZE, lam=LAMBDA_USAGE)\n",
    "\n",
    "        loss = recon_loss + codebook_loss + commit_loss + u_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        cum_loss   += loss.item()\n",
    "        cum_recon  += recon_loss.item()\n",
    "        cum_code   += codebook_loss.item()\n",
    "        cum_commit += commit_loss.item()\n",
    "        cum_usage  += u_loss.item()\n",
    "\n",
    "        if steps % 30 == 0:\n",
    "            avg_loss  = cum_loss   / steps\n",
    "            avg_recon = cum_recon  / steps\n",
    "            avg_code  = cum_code   / steps\n",
    "            avg_commit= cum_commit / steps\n",
    "            avg_usage = cum_usage  / steps\n",
    "            with open(log_path, \"a\") as f:\n",
    "                f.write(f\"[Epoch {epoch} | Step {steps}] avg loss {avg_loss:.4f}, recon {avg_recon:.4f}, code {avg_code:.4f}, commit {avg_commit:.4f}, usage {avg_usage:.4f}\\n\")\n",
    "\n",
    "    # 에폭 말 평균 계산\n",
    "    avg_loss   = cum_loss   / steps\n",
    "    avg_recon  = cum_recon  / steps\n",
    "    avg_code   = cum_code   / steps\n",
    "    avg_commit = cum_commit / steps\n",
    "    avg_usage  = cum_usage  / steps\n",
    "    \n",
    "    # ── epoch 끝: dead-code 재초기화 ───────────────────────\n",
    "    with torch.no_grad():\n",
    "        for l, cb in enumerate(model.rvq.codebooks):\n",
    "            ratio = len(active_sets[l]) / cb.weight.size(0)\n",
    "        if ratio < DEAD_THRESH and epoch > 0:\n",
    "            cb.weight.uniform_(-SIGMA, SIGMA)\n",
    "            print(f\"[Epoch {epoch}] L{l} reset (usage {ratio:.1%})\")\n",
    "\n",
    "    # 스케줄러 업데이트\n",
    "    scheduler.step(avg_recon)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    # 로그 출력\n",
    "    with open(log_path, \"a\") as f:\n",
    "        f.write(f\"=== Epoch {epoch} === avg loss {avg_loss:.4f}, recon {avg_recon:.4f}, code {avg_code:.4f}, commit {avg_commit:.4f}, usage {avg_usage:.4f}, lr {current_lr:.2e}\\n\")\n",
    "    \n",
    "    # trade-off 모델 저장\n",
    "    save_cond = (avg_recon < RECON_THR) and (avg_usage < USAGE_THR)\n",
    "    # if save_cond and avg_loss < best_loss:\n",
    "    if save_cond and avg_loss > 0:\n",
    "        best_loss = avg_loss\n",
    "        ckpt = {\n",
    "            \"encoder\": model.enc.state_dict(),\n",
    "            \"codebooks\": [cb.weight.detach().cpu() for cb in model.rvq.codebooks]\n",
    "        }\n",
    "        torch.save(ckpt, best_model_path)\n",
    "        with open(log_path, \"a\") as f:\n",
    "            f.write(\n",
    "                f\"New best model saved! \"\n",
    "                f\"loss {best_loss:.4f}, recon {avg_recon:.4f}, usage {avg_usage:.4f}\\n\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e85206a4-1ffb-42c7-9e15-908c30ca715b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1023241/5222596.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rvq.codebooks[l].weight.data.copy_(torch.tensor(w))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★ Encoder latent_dim = 128,  RVQ: 12×512 codebooks\n",
      "(306211, 840) float32\n",
      "\n",
      "==== RVQ 평가 결과 ====\n",
      "샘플 수           : 306,211\n",
      "Reconstruction MSE: 1.9310e-06\n",
      "PSNR             : 57.14 dB\n",
      "\n",
      "레벨별 codebook 사용률 / perplexity\n",
      "  Level  0: usage   0.20% | perplexity    1.00\n",
      "  Level  1: usage   0.39% | perplexity    2.00\n",
      "  Level  2: usage   1.17% | perplexity    6.00\n",
      "  Level  3: usage   3.91% | perplexity   20.00\n",
      "  Level  4: usage  14.26% | perplexity   73.00\n",
      "  Level  5: usage  27.34% | perplexity  140.00\n",
      "  Level  6: usage  36.13% | perplexity  185.00\n",
      "  Level  7: usage  42.97% | perplexity  220.00\n",
      "  Level  8: usage  46.68% | perplexity  239.00\n",
      "  Level  9: usage  49.80% | perplexity  255.00\n",
      "  Level 10: usage  56.25% | perplexity  288.00\n",
      "  Level 11: usage  54.88% | perplexity  281.00\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "# 0)  경로 & 환경\n",
    "####################################################################\n",
    "import torch, math, numpy as np, pandas as pd\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "CKPT_PATH  = Path('/home/work/skku/hyo/hyo/model/rvq_best_model_word_5.pt')\n",
    "DATA_PATH  = Path('/home/work/skku/hyo/hyo/dataset/word.parquet')\n",
    "BATCH_SIZE = 256\n",
    "DEVICE     = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "####################################################################\n",
    "# 1)  네트워크 정의 (학습 코드 그대로)\n",
    "####################################################################\n",
    "class RVQ(nn.Module):\n",
    "    \"\"\"Residual Vector Quantization with multiple codebooks.\"\"\"\n",
    "    def __init__(self, num_quantizers=N_Q, num_embeddings=N_EMB, embedding_dim=LATENT_DIM):\n",
    "        super().__init__()\n",
    "        self.num_quantizers = num_quantizers\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.codebooks = nn.ModuleList(\n",
    "            [nn.Embedding(num_embeddings, embedding_dim) for _ in range(num_quantizers)]\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        # z: (B, L, D)\n",
    "        residual = z\n",
    "        quantized = torch.zeros_like(z)\n",
    "        all_indices = []\n",
    "        for codebook in self.codebooks:\n",
    "            weight = codebook.weight  # (K, D)\n",
    "            # compute L2 distance\n",
    "            dist = ((residual.unsqueeze(2) - weight.unsqueeze(0).unsqueeze(0))**2).sum(-1)\n",
    "            indices = dist.argmin(-1)        # (B, L)\n",
    "            all_indices.append(indices)\n",
    "            q = F.embedding(indices, weight) # (B, L, D)\n",
    "            quantized += q\n",
    "            # ── γ 스케줄링: 앞단(0) 0.88 → 뒷단(7) 0.95 ──────────────────\n",
    "            gamma_start, gamma_end = 0.88, 0.95\n",
    "            level = len(all_indices)                      # 현재 레벨 l\n",
    "            gamma = gamma_start + (gamma_end - gamma_start) * (level / (self.num_quantizers - 1))\n",
    "            residual = gamma * (residual - q)\n",
    "            # residual = 0.88 * (residual - q)\n",
    "            # residual = residual - q\n",
    "        return quantized, all_indices\n",
    "\n",
    "class ConvEEGEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    840-dim 벡터를 1×840 시퀀스로 보고 Conv1D 두 층으로 잠재표현 생성\n",
    "    출력은 (B, latent_dim)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=840, latent_dim=LATENT_DIM, hidden=256):\n",
    "        super().__init__()\n",
    "        self.conv_stack = nn.Sequential(\n",
    "            nn.Conv1d(1, hidden, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.Conv1d(hidden, latent_dim, kernel_size=3, padding=1), nn.ReLU()\n",
    "        )\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)   # 길이 840 → 1 로 압축\n",
    "\n",
    "    def forward(self, x):           # x: (B, feat)\n",
    "        x = x.unsqueeze(1)          # (B, 1, 840)\n",
    "        z = self.conv_stack(x)      # (B, latent_dim, 840)\n",
    "        z = self.pool(z).squeeze(-1)  # (B, latent_dim)\n",
    "        return z\n",
    "\n",
    "####################################################################\n",
    "# 2)  체크포인트 로드 → 인스턴스 복원\n",
    "####################################################################\n",
    "ckpt = torch.load(CKPT_PATH, map_location='cpu')\n",
    "\n",
    "# ── encoder ──\n",
    "enc_sd = ckpt['encoder']                     # state_dict (len 4)\n",
    "latent_dim = enc_sd['conv_stack.2.weight'].shape[0]   # out_channels of 2nd conv\n",
    "encoder = ConvEEGEncoder(input_dim=840, latent_dim=latent_dim, hidden=enc_sd['conv_stack.0.weight'].shape[0])\n",
    "encoder.load_state_dict(enc_sd)\n",
    "encoder = encoder.to(DEVICE).eval()\n",
    "\n",
    "# ── RVQ ──\n",
    "codebooks = ckpt['codebooks']                # list of np.arrays\n",
    "n_q    = len(codebooks)\n",
    "K      = codebooks[0].shape[0]\n",
    "rvq    = RVQ(num_quantizers=n_q, num_embeddings=K, embedding_dim=latent_dim)\n",
    "with torch.no_grad():\n",
    "    for l, w in enumerate(codebooks):\n",
    "        rvq.codebooks[l].weight.data.copy_(torch.tensor(w))\n",
    "rvq = rvq.to(DEVICE).eval()\n",
    "\n",
    "print(f\"★ Encoder latent_dim = {latent_dim},  RVQ: {n_q}×{K} codebooks\")\n",
    "\n",
    "####################################################################\n",
    "# 3)  데이터 로드 → DataLoader (raw 840-dim 벡터)\n",
    "####################################################################\n",
    "class EEGVecDataset(Dataset):\n",
    "    \"\"\"\n",
    "    EEG word-level feature 벡터 하나를 그대로 토큰으로 사용.\n",
    "    \"\"\"\n",
    "    def __init__(self, np_array):              # np_array: (N, feat)\n",
    "        mu, std = np_array.mean(0, keepdims=True), np_array.std(0, keepdims=True)+1e-8\n",
    "        self.data = (np_array - mu) / std      # 정규화\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.data[idx])    # shape: (feat,)\n",
    "\n",
    "df = pd.read_parquet(DATA_PATH)\n",
    "\n",
    "eeg_vecs = df[\"eeg\"].to_numpy()\n",
    "\n",
    "arr = np.stack(eeg_vecs).astype(np.float32)\n",
    "arr = np.nan_to_num(arr, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "print(arr.shape, arr.dtype)  # → (N, 840) float32\n",
    "\n",
    "# 5) Dataset & DataLoader\n",
    "ds = EEGVecDataset(arr)             # now each item is (840,) vector\n",
    "loader  = DataLoader(ds, batch_size=256, shuffle=True)\n",
    "\n",
    "####################################################################\n",
    "# 4)  평가 루프  (encoder vs. RVQ 복원)\n",
    "####################################################################\n",
    "mse_tot, code_hist = 0.0, Counter()\n",
    "with torch.no_grad():\n",
    "    for x in loader:                        # x: (B, 840)\n",
    "        x = x.to(DEVICE)                    # (B, 1, 840) → (B, L=1, 840)\n",
    "        z = encoder(x)                      # (B, latent)\n",
    "        z = z.unsqueeze(1)\n",
    "        zq, idx_list = rvq(z)               # (B, latent), (B, n_q)\n",
    "        idx = torch.stack(idx_list, dim=1).squeeze(-1)\n",
    "        mse_tot += torch.mean((z - zq)**2).item() * x.size(0)\n",
    "        for lvl, indices in enumerate(idx.t()):\n",
    "            code_hist.update([(lvl, i.item()) for i in indices])\n",
    "\n",
    "mse  = mse_tot / len(ds)\n",
    "psnr = 10 * math.log10(1.0 / mse)\n",
    "\n",
    "####################################################################\n",
    "# 5)  코드북 사용률·퍼플렉시티\n",
    "####################################################################\n",
    "print(f\"\\n==== RVQ 평가 결과 ====\")\n",
    "print(f\"샘플 수           : {len(ds):,}\")\n",
    "print(f\"Reconstruction MSE: {mse:.4e}\")\n",
    "print(f\"PSNR             : {psnr:.2f} dB\\n\")\n",
    "\n",
    "print(\"레벨별 codebook 사용률 / perplexity\")\n",
    "for lvl in range(n_q):\n",
    "    used = [cid for (lv, cid) in code_hist if lv == lvl]\n",
    "    usage = len(set(used)) / K * 100\n",
    "    entropy = -sum((used.count(c)/len(used))*math.log(used.count(c)/len(used)+1e-9)\n",
    "                   for c in set(used))\n",
    "    perp = math.exp(entropy)\n",
    "    print(f\"  Level {lvl:2d}: usage {usage:6.2f}% | perplexity {perp:7.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c027f67-9e35-4339-9193-33b7d6e76f82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyo",
   "language": "python",
   "name": "hyo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
